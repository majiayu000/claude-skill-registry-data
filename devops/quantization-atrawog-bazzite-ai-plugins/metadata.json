{
  "name": "quantization",
  "repo": "atrawog/bazzite-ai-plugins",
  "category": "devops",
  "description": "Model quantization for efficient inference and training. Covers precisiontypes (FP32, FP16, BF16, INT8, INT4), BitsAndBytes configuration, memoryestimation, and performance tradeoffs.",
  "source": "SkillsMP + GitHub Raw",
  "downloaded_at": "2026-01-06T09:04:04.898653Z",
  "github_path": "bazzite-ai-jupyter/skills/quantization",
  "github_branch": "main",
  "dir_name": "quantization-atrawog-bazzite-ai-plugins"
}