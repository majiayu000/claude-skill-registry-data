{
  "name": "peft",
  "repo": "atrawog/bazzite-ai-plugins",
  "category": "devops",
  "description": "Parameter-efficient fine-tuning with LoRA and Unsloth. Covers LoraConfig,target module selection, QLoRA for 4-bit training, adapter merging, andUnsloth optimizations for 2x faster training.",
  "source": "SkillsMP + GitHub Raw",
  "downloaded_at": "2026-01-06T09:04:04.897101Z",
  "github_path": "bazzite-ai-jupyter/skills/peft",
  "github_branch": "main",
  "dir_name": "peft-atrawog-bazzite-ai-plugins"
}