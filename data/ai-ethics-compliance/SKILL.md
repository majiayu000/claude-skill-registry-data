---
name: AI Ethics and Compliance
description: Navigating the regulatory landscape and ethical frameworks for responsible AI development and deployment.
---

# AI Ethics and Compliance

## Overview

AI Ethics and Compliance involve building systems that are not only technically proficient but also socially responsible and legally compliant. This includes adhering to global regulations and internal ethical guidelines regarding privacy, security, and human rights.

**Core Principle**: "Just because you *can* build it, doesn't mean you *should*."

---

## 1. Principles of Ethical AI

The industry generally agrees on these four pillars:

1.  **Transparency**: Can we explain how the system reached its decision?
2.  **Accountability**: Who is responsible if the AI causes harm (Producer, Operator, or User)?
3.  **Privacy & Security**: Is data handled according to GDPR/CCPA? Is the model resistant to adversarial attacks?
4.  **Beneficence**: Does the AI provide a clear benefit to society while minimizing harm?

---

## 2. The Regulatory Landscape

| Regulation | Region | Key Requirement |
| :--- | :--- | :--- |
| **EU AI Act** | Europe | Risk-based classification (Prohibited, High-Risk, Limited). |
| **NIST AI RMF** | USA | Voluntary framework for managing AI risk and trustworthiness. |
| **Bletchley Declaration**| Global | Focus on "Frontier AI" safety and catastrophic risk. |
| **CA AI Safety Bill** | California | Requirements for testing large models for lethal or cyber-attack risk. |

---

## 3. High-Risk AI Classification (EU AI Act)

The EU AI Act categorizes AI based on risk to human safety and fundamental rights:

*   **Unacceptable Risk**: (Prohibited) Social scoring, biometric identification in public spaces, dark pattern manipulation.
*   **High-Risk**: Recruitment, credit scoring, healthcare, critical infrastructure. (Requires strict audits, documentation, and human oversight).
*   **Limited Risk**: Chatbots (must be transparent that they are AI).
*   **Minimal Risk**: Spam filters, AI in video games.

---

## 4. AI Impact Assessment (AIIA)

An **Algorithmic Impact Assessment** should be conducted before building any high-risk system.

### AIIA Template Questions:
1.  **Purpose**: What problem is the AI trying to solve?
2.  **Data Source**: Where is the data coming from? Is there consent?
3.  **Impact**: What happens if the model is wrong (False Positive vs. False Negative)?
4.  **Mitigation**: How are we measuring bias and ensuring security?
5.  **Human Oversight**: Is there a "Kill Switch" or manual override?

---

## 5. Algorithmic Auditing

Formal audits performed by internal teams or external third-parties to verify:
*   **Accuracy & Reliability**: Does it perform as claimed?
*   **Fairness**: Are metrics within acceptable bounds (see `model-bias-fairness`)?
*   **Security**: Can the model be tricked into revealing training data (Data Leakage)?
*   **Sustainability**: What is the carbon footprint of training this model?

---

## 6. Transparency: The "nutrition label" for AI

Implement **AI Disclosure** in the product:
*   "This image was generated by AI."
*   "A human reviewer has checked this decision."
*   "Our algorithm uses [Feature A] and [Feature B] to determine your score."

---

## 7. Human-in-the-Loop (HITL)

Compliance often requires that significant decisions (legal, medical, financial) cannot be made by AI alone.

| Pattern | Description |
| :--- | :--- |
| **Human IN the loop** | AI provides a recommendation; human clicks "Approve". |
| **Human ON the loop** | AI makes decisions, human monitors and intervenes if needed. |
| **Human OUT of the loop**| Fully automated (forbidden for high-risk systems under some laws). |

---

## 8. Generative AI Ethics (LLMs)

Specific risks for Large Language Models:
*   **Hallucination**: AI presenting false info as fact.
*   **IP Infringement**: Training on copyrighted material without consent.
*   **Harmful Content**: Jailbreaking to generate instructions for illegal acts.
*   **Deepfakes**: Creating non-consensual realistic images/audio of people.

---

## 9. Tools and Resources

1.  **IBM AI Ethics Board**: A blueprint for corporate ethics governance.
2.  **EthicsGrade**: Platforms for rating company AI ethical maturity.
3.  **Trustible**: Compliance management software for the EU AI Act.
4.  **OECD AI Policy Observatory**: Global tracking of AI policies.

---

## 10. AI Ethics and Compliance Checklist

- [ ] **Risk Tier**: Have we classified our project under the EU AI Act tiers?
- [ ] **Transparency**: Is the user aware they are interacting with an AI?
- [ ] **Impact Assessment**: Have we completed an AIIA before development?
- [ ] **PII Protection**: Is training data anonymized according to HIPAA/GDPR?
- [ ] **Human Oversight**: Is there a clear path for a user to appeal an AI decision?
- [ ] **Copyright**: Do we have the legal right to use the training data?
- [ ] **Ethics Review**: Has the Ethics Board reviewed the "intended use" vs "actual use"?

---

## Related Skills
* `44-ai-governance/model-bias-fairness`
* `44-ai-governance/model-risk-management`
* `43-data-reliability/data-retention-archining` (privacy compliance)
