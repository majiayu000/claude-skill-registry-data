{
  "name": "unsloth-finetuning",
  "repo": "ScientiaCapital/unsloth-mcp-server",
  "category": "data",
  "description": "Fine-tune LLMs 2x faster with 80% less memory using Unsloth. Use when the user wants to fine-tune models like Llama, Mistral, Phi, or Gemma. Handles model loading, LoRA configuration, training, and mo",
  "source": "SkillsMP + GitHub Raw",
  "downloaded_at": "2026-01-06T09:03:27.895602Z",
  "dir_name": "unsloth-finetuning",
  "github_path": ".claude/skills/unsloth-finetuning",
  "github_branch": "main"
}