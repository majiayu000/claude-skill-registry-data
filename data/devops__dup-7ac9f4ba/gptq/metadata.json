{
  "name": "gptq",
  "repo": "zechenzhangAGI/AI-research-SKILLs",
  "category": "devops",
  "description": "Post-training 4-bit quantization for LLMs with minimal accuracy loss. Use for deploying large models (70B, 405B) on consumer GPUs, when you need 4Ã— memory reduction with <2% perplexity degradation, or",
  "source": "SkillsMP + GitHub Raw",
  "downloaded_at": "2026-01-06T08:56:19.044624Z",
  "github_path": "10-optimization/gptq",
  "github_branch": "main"
}