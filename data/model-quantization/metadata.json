{
  "name": "model-quantization",
  "description": "Expert skill for AI model quantization and optimization. Covers 4-bit/8-bit quantization, GGUF conversion, memory optimization, and quality-performance tradeoffs for deploying LLMs in resource-constra",
  "repo": "martinholovsky/claude-skills-generator",
  "category": "other",
  "tags": [],
  "stars": 0,
  "source": "github.com/martinholovsky/claude-skills-generator"
}