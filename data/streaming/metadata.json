{
  "name": "streaming",
  "description": "Use when building real-time chat interfaces, displaying incremental LLM responses, or streaming output from OpenAI, Anthropic, Google, or Ollama - async iteration with usage tracking works across all ",
  "repo": "juanre/llmring",
  "category": "data",
  "tags": [
    "streaming"
  ],
  "stars": 3,
  "source": "local",
  "dir_name": "streaming"
}