{
  "name": "grey-haven-evaluation",
  "repo": "greyhaven-ai/claude-code-config",
  "category": "product",
  "description": "Evaluate LLM outputs with multi-dimensional rubrics, handle non-determinism, and implement LLM-as-judge patterns. Essential for production LLM systems. Use when testing prompts, validating outputs, co",
  "source": "SkillsMP + GitHub Raw",
  "downloaded_at": "2026-01-06T08:58:12.731423Z"
}