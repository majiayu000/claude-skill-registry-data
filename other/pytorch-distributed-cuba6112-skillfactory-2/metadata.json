{
  "name": "pytorch-distributed",
  "description": "Distributed training strategies including DistributedDataParallel (DDP) and Fully Sharded Data Parallel (FSDP). Covers multi-node setup, checkpointing, and process management using torchrun. (ddp, fsd",
  "repo": "cuba6112/skillfactory",
  "path": "skills/pytorch-distributed",
  "category": "other",
  "tags": [],
  "stars": 0,
  "source": "github.com/cuba6112/skillfactory",
  "dir_name": "pytorch-distributed-cuba6112-skillfactory-2"
}