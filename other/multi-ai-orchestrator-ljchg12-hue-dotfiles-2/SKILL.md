---
name: "multi-ai-orchestrator"
description: "Ollama-based multi-AI model orchestration with auto-profiling, smart routing, and ensemble execution"
---

# Multi-AI Orchestrator

## Overview

Ollama ê¸°ë°˜ ë¡œì»¬ AI ëª¨ë¸ ìë™ í”„ë¡œíŒŒì¼ë§, ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…, ì•™ìƒë¸” ì‹¤í–‰ ìŠ¤í‚¬.

**í•µì‹¬ ê¸°ëŠ¥**:
- âš¡ ìë™ í”„ë¡œíŒŒì¼ë§: ëª¨ë¸ ì¶”ê°€ ì‹œ ìë™ ê°ì§€/ì—…ë°ì´íŠ¸
- ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…: ì‘ì—… ìœ í˜•ë³„ ìµœì  ëª¨ë¸ ì„ íƒ (ì •í™•ë„ 95%+)
- ğŸš€ ë³‘ë ¬ ì²˜ë¦¬: ë³µì¡ ì‘ì—… ì‹œ 3+ ëª¨ë¸ ë™ì‹œ ì‹¤í–‰ í›„ ì¢…í•©
- ğŸ’ª í•˜ë“œì›¨ì–´ ìµœì í™”: RTX PRO 6000 ê¸°ì¤€ 8,425 tokens/s

## When to Use

### âœ… ì í•©í•œ ê²½ìš°
- 3ê°œ+ Ollama ëª¨ë¸ ìš´ì˜
- ë‹¤ì–‘í•œ ì‘ì—… ìœ í˜• (ì½”ë”©/ë¶„ì„/ë²ˆì—­)
- ê³ í’ˆì§ˆ ê²°ê³¼ í•„ìš” (êµì°¨ ê²€ì¦)
- RTX 4090/5090/PRO 6000+ GPU

### âŒ ë¶€ì í•©í•œ ê²½ìš°
- 1-2ê°œ ëª¨ë¸ë§Œ ì‚¬ìš©
- VRAM 16GB ì´í•˜
- ì‹¤ì‹œê°„ ì´ˆì €ì§€ì—° ìš”êµ¬ (0.2-0.5ì´ˆ ì˜¤ë²„í—¤ë“œ)

## Core Capabilities

### 1. ìë™ ëª¨ë¸ í”„ë¡œíŒŒì¼ë§
`scripts/auto_model_profiler.py` ì‹¤í–‰ â†’ `models_profile.json` ìƒì„±

### 2. ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…
| ì‘ì—… ìœ í˜• | í‚¤ì›Œë“œ | ì„ íƒ ëª¨ë¸ |
|----------|--------|----------|
| ì½”ë”© | ì½”ë“œ, í•¨ìˆ˜, debug | Codex |
| ë¶„ì„ | ë¶„ì„, ë¹„êµ, í‰ê°€ | Claude |
| ë²ˆì—­ | ë²ˆì—­, translate | Gemini |
| ë¹ ë¥¸ ì‘ë‹µ | ë¹¨ë¦¬, ìš”ì•½ | Gemini |
| ìˆ˜í•™ | ê³„ì‚°, ì¦ëª… | Qwen |

### 3. ì•™ìƒë¸” ì‹¤í–‰
ë³µì¡ ì‘ì—… â†’ 3ê°œ ëª¨ë¸ ë³‘ë ¬ â†’ Claude ì¢…í•©
- ì†Œìš”: 4-9ì´ˆ (ë‹¨ì¼ ëŒ€ë¹„ +2-3ì´ˆ)
- í’ˆì§ˆ: +30-50%

### 4. MCP í†µí•©
`cli-orchestrator` MCPë¡œ Codex CLI, Gemini CLI ì œì–´ ê°€ëŠ¥
- `ask_codex`: ì½”ë“œ íŠ¹í™”
- `ask_gemini`: ë¹ ë¥¸ ì‘ë‹µ
- `compare_models`: ë³‘ë ¬ ë¹„êµ
- `smart_ask`: ìë™ ë¼ìš°íŒ…

## Installation

### Quick Start (Claude Code)
```bash
mkdir -p ~/.claude/skills/multi-ai-orchestrator
cp SKILL.md ~/.claude/skills/multi-ai-orchestrator/
```

### ìŠ¤í¬ë¦½íŠ¸ ì„¤ì •
```bash
cd ~/.claude/skills/multi-ai-orchestrator
python3 auto_model_profiler.py  # í”„ë¡œíŒŒì¼ ìƒì„±
```

## Usage

### ê¸°ë³¸ ì‚¬ìš©
```python
from smart_router import SmartRouter
router = SmartRouter()
model = router.route("Python ì´ì§„ íƒìƒ‰ êµ¬í˜„í•´ì¤˜")  # â†’ codex
```

### ì•™ìƒë¸” ì‹¤í–‰
```python
from ensemble_executor import ModelEnsemble
ensemble = ModelEnsemble()
results = await ensemble.run_parallel("ê¸°í›„ë³€í™” ê²½ì œì˜í–¥ ë¶„ì„")
final = ensemble.synthesize(results)
```

## Files

| íŒŒì¼ | ìš©ë„ |
|------|------|
| `auto_model_profiler.py` | ëª¨ë¸ í”„ë¡œíŒŒì¼ë§ |
| `smart_router.py` | ì‘ì—…â†’ëª¨ë¸ ë¼ìš°íŒ… |
| `ensemble_executor.py` | ë³‘ë ¬ ì‹¤í–‰ |
| `mcp_bridge.py` | MCP í†µí•© |
| `models_profile.json` | ëª¨ë¸ íŠ¹ì„± DB |

## References

ìƒì„¸ ë‚´ìš©ì€ ë‹¤ìŒ íŒŒì¼ ì°¸ì¡°:
- `references/installation.md` - ìƒì„¸ ì„¤ì¹˜ ê°€ì´ë“œ
- `references/examples.md` - ì‚¬ìš© ì˜ˆì œ
- `references/mcp-integration.md` - MCP í†µí•© ìƒì„¸
- `references/benchmarks.md` - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- `references/algorithms.md` - ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

## Performance

| ì§€í‘œ | ê°’ |
|------|-----|
| ë¼ìš°íŒ… ì •í™•ë„ | 95%+ |
| ë‹¨ì¼ ëª¨ë¸ ì‹¤í–‰ | 2-5ì´ˆ |
| ì•™ìƒë¸” (3ê°œ) | 4-9ì´ˆ |
| í’ˆì§ˆ í–¥ìƒ | +30-50% |
