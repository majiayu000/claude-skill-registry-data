---
name: gemini-integration
description: |
  Google Gemini API é›†æˆæŒ‡å—ï¼šæä¾› AI åˆ†æã€æç¤ºè¯å·¥ç¨‹ã€æµå¼å“åº”å’Œå¤šæ¨¡æ€å¤„ç†çš„æœ€ä½³å®è·µã€‚
  Use when: éœ€è¦é›†æˆ Gemini APIã€ç¼–å†™æç¤ºè¯ã€å¤„ç†æµå¼å“åº”ã€å¤šæ¨¡æ€è¾“å…¥ã€‚
  Triggers: "Gemini", "AI", "LLM", "æç¤ºè¯", "prompt", "æµå¼", "streaming", "å¤šæ¨¡æ€"
category: ai-integration
---

# Gemini Integration (Google Gemini API é›†æˆæŒ‡å—)

> ğŸ¤– **æ ¸å¿ƒç†å¿µ**: æ ‡å‡†åŒ– Gemini API é›†æˆæµç¨‹ï¼Œç¡®ä¿ AI åŠŸèƒ½çš„å¯é æ€§ã€æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚

## When to Use This Skill

ä½¿ç”¨æ­¤æŠ€èƒ½å½“ä½ éœ€è¦ï¼š
- é›†æˆ Google Gemini API è¿›è¡Œ AI åˆ†æ
- ç¼–å†™å’Œä¼˜åŒ–æç¤ºè¯ (Prompt Engineering)
- å®ç°æµå¼å“åº” (Streaming Response)
- å¤„ç†å¤šæ¨¡æ€è¾“å…¥ (æ–‡æœ¬ã€å›¾ç‰‡ã€æ–‡æ¡£)
- æ„å»ºé‡‘èåˆ†æ AI åŠŸèƒ½
- å®ç°å¤šè½®å¯¹è¯ç³»ç»Ÿ

## Not For / Boundaries

æ­¤æŠ€èƒ½ä¸é€‚ç”¨äºï¼š
- å…¶ä»– LLM æä¾›å•† (OpenAI, Claude ç­‰)
- æœ¬åœ°æ¨¡å‹éƒ¨ç½²
- æ¨¡å‹å¾®è°ƒ (Fine-tuning)

---

## Quick Reference

### ğŸ¯ Gemini é›†æˆæ ‡å‡†å·¥ä½œæµ

```
éœ€æ±‚åˆ†æ â†’ æ¨¡å‹é€‰æ‹© â†’ æç¤ºè¯è®¾è®¡ â†’ API é›†æˆ â†’ æµå¼å¤„ç† â†’ æµ‹è¯•éªŒè¯
    â†“          â†“           â†“           â†“          â†“          â†“
  åœºæ™¯å®šä¹‰   æ€§èƒ½/æˆæœ¬   ç»“æ„åŒ–è¾“å‡º   é”™è¯¯å¤„ç†   ç”¨æˆ·ä½“éªŒ   è´¨é‡è¯„ä¼°
```

### ğŸ“‹ é›†æˆå‰å¿…é—®æ¸…å•

| é—®é¢˜ | ç›®çš„ |
|------|------|
| 1. ä½¿ç”¨å“ªä¸ªæ¨¡å‹ï¼Ÿ | gemini-2.0-flash / gemini-1.5-pro |
| 2. éœ€è¦æµå¼å“åº”å—ï¼Ÿ | é•¿æ–‡æœ¬ç”Ÿæˆå»ºè®®æµå¼ |
| 3. è¾“å…¥ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ | çº¯æ–‡æœ¬ / å›¾ç‰‡ / æ–‡æ¡£ |
| 4. è¾“å‡ºæ ¼å¼è¦æ±‚ï¼Ÿ | è‡ªç”±æ–‡æœ¬ / JSON / ç»“æ„åŒ– |
| 5. ä¸Šä¸‹æ–‡é•¿åº¦éœ€æ±‚ï¼Ÿ | å½±å“æ¨¡å‹é€‰æ‹©å’Œæˆæœ¬ |
| 6. å®‰å…¨è¿‡æ»¤çº§åˆ«ï¼Ÿ | é‡‘èåœºæ™¯éœ€è¦é€‚å½“é…ç½® |

### ğŸ” æ¨¡å‹é€‰æ‹©æŒ‡å—

| æ¨¡å‹ | é€‚ç”¨åœºæ™¯ | ç‰¹ç‚¹ |
|------|----------|------|
| `gemini-2.0-flash` | é€šç”¨ä»»åŠ¡ã€å¿«é€Ÿå“åº” | é€Ÿåº¦å¿«ã€æˆæœ¬ä½ |
| `gemini-1.5-pro` | å¤æ‚åˆ†æã€é•¿ä¸Šä¸‹æ–‡ | èƒ½åŠ›å¼ºã€ä¸Šä¸‹æ–‡é•¿ |
| `gemini-1.5-flash` | å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ | ä¸­ç­‰é€Ÿåº¦å’Œèƒ½åŠ› |

---

## API é›†æˆåŸºç¡€

### ç¯å¢ƒé…ç½®

```bash
# .env.local
GEMINI_API_KEY=your_api_key_here

# Vercel ç¯å¢ƒå˜é‡åŒæ­¥
vercel env add GEMINI_API_KEY production
vercel env add GEMINI_API_KEY preview
```

### åŸºç¡€å®¢æˆ·ç«¯é…ç½®

```typescript
// src/services/ai/gemini-client.ts
import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from '@google/generative-ai';

// åˆå§‹åŒ–å®¢æˆ·ç«¯
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

// å®‰å…¨è®¾ç½® (é‡‘èåœºæ™¯æ¨è)
const safetySettings = [
  {
    category: HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
  },
];

// ç”Ÿæˆé…ç½®
const generationConfig = {
  temperature: 0.7,        // åˆ›é€ æ€§ (0-1)
  topP: 0.95,              // æ ¸é‡‡æ ·
  topK: 40,                // Top-K é‡‡æ ·
  maxOutputTokens: 8192,   // æœ€å¤§è¾“å‡ºé•¿åº¦
};

// è·å–æ¨¡å‹å®ä¾‹
export function getModel(modelName = 'gemini-2.0-flash') {
  return genAI.getGenerativeModel({
    model: modelName,
    safetySettings,
    generationConfig,
  });
}

// è·å–æµå¼æ¨¡å‹
export function getStreamingModel(modelName = 'gemini-2.0-flash') {
  return genAI.getGenerativeModel({
    model: modelName,
    safetySettings,
    generationConfig,
  });
}
```

### åŸºç¡€æ–‡æœ¬ç”Ÿæˆ

```typescript
// src/services/ai/generate.ts
import { getModel } from './gemini-client';

export async function generateText(prompt: string): Promise<string> {
  const model = getModel();
  
  try {
    const result = await model.generateContent(prompt);
    const response = result.response;
    return response.text();
  } catch (error) {
    console.error('[Gemini] ç”Ÿæˆå¤±è´¥:', error);
    throw new GeminiError('æ–‡æœ¬ç”Ÿæˆå¤±è´¥', error);
  }
}

// è‡ªå®šä¹‰é”™è¯¯ç±»
export class GeminiError extends Error {
  constructor(message: string, public readonly cause?: unknown) {
    super(message);
    this.name = 'GeminiError';
  }
}
```

---

## æµå¼å“åº”å¤„ç†

### æœåŠ¡ç«¯æµå¼ç”Ÿæˆ

```typescript
// src/services/ai/streaming.ts
import { getStreamingModel } from './gemini-client';

/**
 * æµå¼ç”Ÿæˆæ–‡æœ¬
 * @param prompt æç¤ºè¯
 * @param onChunk æ¯ä¸ª chunk çš„å›è°ƒ
 */
export async function generateStream(
  prompt: string,
  onChunk: (chunk: string) => void
): Promise<string> {
  const model = getStreamingModel();
  
  try {
    const result = await model.generateContentStream(prompt);
    let fullText = '';
    
    for await (const chunk of result.stream) {
      const chunkText = chunk.text();
      fullText += chunkText;
      onChunk(chunkText);
    }
    
    return fullText;
  } catch (error) {
    console.error('[Gemini] æµå¼ç”Ÿæˆå¤±è´¥:', error);
    throw new GeminiError('æµå¼ç”Ÿæˆå¤±è´¥', error);
  }
}
```

### API Route æµå¼å“åº”

```typescript
// app/api/ai/stream/route.ts
import { getStreamingModel } from '@/services/ai/gemini-client';

export async function POST(request: Request) {
  const { prompt, systemPrompt } = await request.json();
  
  const model = getStreamingModel();
  
  // åˆ›å»º ReadableStream
  const stream = new ReadableStream({
    async start(controller) {
      try {
        const fullPrompt = systemPrompt 
          ? `${systemPrompt}\n\n${prompt}` 
          : prompt;
          
        const result = await model.generateContentStream(fullPrompt);
        
        for await (const chunk of result.stream) {
          const text = chunk.text();
          // å‘é€ SSE æ ¼å¼æ•°æ®
          controller.enqueue(
            new TextEncoder().encode(`data: ${JSON.stringify({ text })}\n\n`)
          );
        }
        
        // å‘é€ç»“æŸä¿¡å·
        controller.enqueue(
          new TextEncoder().encode('data: [DONE]\n\n')
        );
        controller.close();
      } catch (error) {
        controller.enqueue(
          new TextEncoder().encode(
            `data: ${JSON.stringify({ error: 'ç”Ÿæˆå¤±è´¥' })}\n\n`
          )
        );
        controller.close();
      }
    },
  });
  
  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}
```

### å‰ç«¯æµå¼æ¶ˆè´¹

```typescript
// src/hooks/useStreamingChat.ts
import { useState, useCallback } from 'react';

interface UseStreamingChatOptions {
  onChunk?: (chunk: string) => void;
  onComplete?: (fullText: string) => void;
  onError?: (error: Error) => void;
}

export function useStreamingChat(options: UseStreamingChatOptions = {}) {
  const [isStreaming, setIsStreaming] = useState(false);
  const [streamedText, setStreamedText] = useState('');
  
  const sendMessage = useCallback(async (prompt: string, systemPrompt?: string) => {
    setIsStreaming(true);
    setStreamedText('');
    
    try {
      const response = await fetch('/api/ai/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ prompt, systemPrompt }),
      });
      
      if (!response.ok) {
        throw new Error('è¯·æ±‚å¤±è´¥');
      }
      
      const reader = response.body?.getReader();
      if (!reader) throw new Error('æ— æ³•è¯»å–å“åº”');
      
      const decoder = new TextDecoder();
      let fullText = '';
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') continue;
            
            try {
              const parsed = JSON.parse(data);
              if (parsed.text) {
                fullText += parsed.text;
                setStreamedText(fullText);
                options.onChunk?.(parsed.text);
              }
              if (parsed.error) {
                throw new Error(parsed.error);
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
      }
      
      options.onComplete?.(fullText);
      return fullText;
    } catch (error) {
      const err = error instanceof Error ? error : new Error('æœªçŸ¥é”™è¯¯');
      options.onError?.(err);
      throw err;
    } finally {
      setIsStreaming(false);
    }
  }, [options]);
  
  return {
    sendMessage,
    isStreaming,
    streamedText,
  };
}
```

### æµå¼å“åº” UI ç»„ä»¶

```typescript
// src/components/StreamingMessage.tsx
'use client';

import { useStreamingChat } from '@/hooks/useStreamingChat';
import { useState } from 'react';

export function StreamingMessage() {
  const [input, setInput] = useState('');
  const { sendMessage, isStreaming, streamedText } = useStreamingChat({
    onComplete: (text) => {
      console.log('ç”Ÿæˆå®Œæˆ:', text.length, 'å­—ç¬¦');
    },
  });
  
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!input.trim() || isStreaming) return;
    
    await sendMessage(input);
    setInput('');
  };
  
  return (
    <div className="space-y-4">
      <form onSubmit={handleSubmit} className="flex gap-2">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="è¾“å…¥é—®é¢˜..."
          className="flex-1 px-4 py-2 border rounded-lg"
          disabled={isStreaming}
        />
        <button
          type="submit"
          disabled={isStreaming}
          className="px-4 py-2 bg-blue-500 text-white rounded-lg disabled:opacity-50"
        >
          {isStreaming ? 'ç”Ÿæˆä¸­...' : 'å‘é€'}
        </button>
      </form>
      
      {streamedText && (
        <div className="p-4 bg-gray-50 rounded-lg whitespace-pre-wrap">
          {streamedText}
          {isStreaming && <span className="animate-pulse">â–Š</span>}
        </div>
      )}
    </div>
  );
}
```

---

## å¤šæ¨¡æ€è¾“å…¥å¤„ç†

### å›¾ç‰‡åˆ†æ

```typescript
// src/services/ai/vision.ts
import { getModel } from './gemini-client';

/**
 * åˆ†æå›¾ç‰‡å†…å®¹
 */
export async function analyzeImage(
  imageBase64: string,
  mimeType: string,
  prompt: string
): Promise<string> {
  const model = getModel('gemini-1.5-pro'); // è§†è§‰ä»»åŠ¡æ¨è pro æ¨¡å‹
  
  const imagePart = {
    inlineData: {
      data: imageBase64,
      mimeType,
    },
  };
  
  try {
    const result = await model.generateContent([prompt, imagePart]);
    return result.response.text();
  } catch (error) {
    console.error('[Gemini] å›¾ç‰‡åˆ†æå¤±è´¥:', error);
    throw new GeminiError('å›¾ç‰‡åˆ†æå¤±è´¥', error);
  }
}

/**
 * ä» URL åˆ†æå›¾ç‰‡
 */
export async function analyzeImageFromUrl(
  imageUrl: string,
  prompt: string
): Promise<string> {
  // è·å–å›¾ç‰‡æ•°æ®
  const response = await fetch(imageUrl);
  const arrayBuffer = await response.arrayBuffer();
  const base64 = Buffer.from(arrayBuffer).toString('base64');
  const mimeType = response.headers.get('content-type') || 'image/jpeg';
  
  return analyzeImage(base64, mimeType, prompt);
}
```

### æ–‡æ¡£åˆ†æ

```typescript
// src/services/ai/document.ts
import { getModel } from './gemini-client';

/**
 * åˆ†æ PDF æ–‡æ¡£
 */
export async function analyzePDF(
  pdfBase64: string,
  prompt: string
): Promise<string> {
  const model = getModel('gemini-1.5-pro');
  
  const pdfPart = {
    inlineData: {
      data: pdfBase64,
      mimeType: 'application/pdf',
    },
  };
  
  try {
    const result = await model.generateContent([prompt, pdfPart]);
    return result.response.text();
  } catch (error) {
    console.error('[Gemini] PDF åˆ†æå¤±è´¥:', error);
    throw new GeminiError('PDF åˆ†æå¤±è´¥', error);
  }
}

/**
 * åˆ†æå¤šä¸ªæ–‡ä»¶
 */
export async function analyzeMultipleFiles(
  files: Array<{ data: string; mimeType: string }>,
  prompt: string
): Promise<string> {
  const model = getModel('gemini-1.5-pro');
  
  const parts = files.map(file => ({
    inlineData: {
      data: file.data,
      mimeType: file.mimeType,
    },
  }));
  
  try {
    const result = await model.generateContent([prompt, ...parts]);
    return result.response.text();
  } catch (error) {
    console.error('[Gemini] å¤šæ–‡ä»¶åˆ†æå¤±è´¥:', error);
    throw new GeminiError('å¤šæ–‡ä»¶åˆ†æå¤±è´¥', error);
  }
}
```

---

## å¤šè½®å¯¹è¯

### å¯¹è¯ç®¡ç†

```typescript
// src/services/ai/chat.ts
import { getModel } from './gemini-client';
import type { Content } from '@google/generative-ai';

export interface ChatMessage {
  role: 'user' | 'model';
  content: string;
}

/**
 * åˆ›å»ºå¯¹è¯ä¼šè¯
 */
export function createChatSession(systemPrompt?: string) {
  const model = getModel();
  
  const history: Content[] = [];
  
  // å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯
  if (systemPrompt) {
    history.push({
      role: 'user',
      parts: [{ text: `ç³»ç»ŸæŒ‡ä»¤: ${systemPrompt}` }],
    });
    history.push({
      role: 'model',
      parts: [{ text: 'æˆ‘å·²ç†è§£ç³»ç»ŸæŒ‡ä»¤ï¼Œå‡†å¤‡å¥½ä¸ºæ‚¨æœåŠ¡ã€‚' }],
    });
  }
  
  const chat = model.startChat({ history });
  
  return {
    /**
     * å‘é€æ¶ˆæ¯
     */
    async sendMessage(message: string): Promise<string> {
      const result = await chat.sendMessage(message);
      return result.response.text();
    },
    
    /**
     * æµå¼å‘é€æ¶ˆæ¯
     */
    async sendMessageStream(
      message: string,
      onChunk: (chunk: string) => void
    ): Promise<string> {
      const result = await chat.sendMessageStream(message);
      let fullText = '';
      
      for await (const chunk of result.stream) {
        const text = chunk.text();
        fullText += text;
        onChunk(text);
      }
      
      return fullText;
    },
    
    /**
     * è·å–å¯¹è¯å†å²
     */
    getHistory(): ChatMessage[] {
      return chat.getHistory().map(msg => ({
        role: msg.role as 'user' | 'model',
        content: msg.parts.map(p => (p as { text: string }).text).join(''),
      }));
    },
  };
}
```

### å¯¹è¯ Hook

```typescript
// src/hooks/useChat.ts
import { useState, useCallback, useRef } from 'react';
import { createChatSession, ChatMessage } from '@/services/ai/chat';

export function useChat(systemPrompt?: string) {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const chatRef = useRef(createChatSession(systemPrompt));
  
  const sendMessage = useCallback(async (content: string) => {
    setIsLoading(true);
    
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    setMessages(prev => [...prev, { role: 'user', content }]);
    
    try {
      // æ·»åŠ ç©ºçš„ AI æ¶ˆæ¯ç”¨äºæµå¼æ›´æ–°
      setMessages(prev => [...prev, { role: 'model', content: '' }]);
      
      await chatRef.current.sendMessageStream(content, (chunk) => {
        setMessages(prev => {
          const newMessages = [...prev];
          const lastMessage = newMessages[newMessages.length - 1];
          if (lastMessage.role === 'model') {
            lastMessage.content += chunk;
          }
          return newMessages;
        });
      });
    } catch (error) {
      // ç§»é™¤ç©ºçš„ AI æ¶ˆæ¯
      setMessages(prev => prev.slice(0, -1));
      throw error;
    } finally {
      setIsLoading(false);
    }
  }, []);
  
  const reset = useCallback(() => {
    chatRef.current = createChatSession(systemPrompt);
    setMessages([]);
  }, [systemPrompt]);
  
  return {
    messages,
    sendMessage,
    isLoading,
    reset,
  };
}
```

---

## ç»“æ„åŒ–è¾“å‡º

### JSON è¾“å‡º

```typescript
// src/services/ai/structured.ts
import { getModel } from './gemini-client';

/**
 * ç”Ÿæˆç»“æ„åŒ– JSON è¾“å‡º
 */
export async function generateJSON<T>(
  prompt: string,
  schema: string
): Promise<T> {
  const model = getModel();
  
  const structuredPrompt = `
${prompt}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
${schema}

åªè¾“å‡º JSONï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šæˆ– markdown æ ¼å¼ã€‚
`;
  
  try {
    const result = await model.generateContent(structuredPrompt);
    const text = result.response.text();
    
    // æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—
    const cleanedText = text
      .replace(/```json\n?/g, '')
      .replace(/```\n?/g, '')
      .trim();
    
    return JSON.parse(cleanedText) as T;
  } catch (error) {
    console.error('[Gemini] JSON ç”Ÿæˆå¤±è´¥:', error);
    throw new GeminiError('JSON ç”Ÿæˆå¤±è´¥', error);
  }
}

// ä½¿ç”¨ç¤ºä¾‹
interface StockAnalysis {
  symbol: string;
  recommendation: 'buy' | 'hold' | 'sell';
  targetPrice: number;
  riskLevel: 'low' | 'medium' | 'high';
  reasons: string[];
}

const analysis = await generateJSON<StockAnalysis>(
  'åˆ†æè‹¹æœå…¬å¸ (AAPL) çš„è‚¡ç¥¨',
  `{
    "symbol": "string",
    "recommendation": "buy | hold | sell",
    "targetPrice": "number",
    "riskLevel": "low | medium | high",
    "reasons": ["string"]
  }`
);
```

---

## é”™è¯¯å¤„ç†

### Gemini ç‰¹å®šé”™è¯¯

```typescript
// src/services/ai/errors.ts

export class GeminiError extends Error {
  constructor(
    message: string,
    public readonly cause?: unknown,
    public readonly code?: string
  ) {
    super(message);
    this.name = 'GeminiError';
  }
}

export class GeminiRateLimitError extends GeminiError {
  constructor(retryAfter?: number) {
    super(`API è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯· ${retryAfter || 60} ç§’åé‡è¯•`);
    this.name = 'GeminiRateLimitError';
  }
}

export class GeminiSafetyError extends GeminiError {
  constructor(public readonly blockedCategories: string[]) {
    super('å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆª');
    this.name = 'GeminiSafetyError';
  }
}

export class GeminiQuotaError extends GeminiError {
  constructor() {
    super('API é…é¢å·²ç”¨å°½');
    this.name = 'GeminiQuotaError';
  }
}

/**
 * å¤„ç† Gemini API é”™è¯¯
 */
export function handleGeminiError(error: unknown): never {
  if (error instanceof GeminiError) {
    throw error;
  }
  
  const errorMessage = error instanceof Error ? error.message : String(error);
  
  // é€Ÿç‡é™åˆ¶
  if (errorMessage.includes('429') || errorMessage.includes('rate limit')) {
    throw new GeminiRateLimitError();
  }
  
  // é…é¢ç”¨å°½
  if (errorMessage.includes('quota') || errorMessage.includes('billing')) {
    throw new GeminiQuotaError();
  }
  
  // å®‰å…¨è¿‡æ»¤
  if (errorMessage.includes('safety') || errorMessage.includes('blocked')) {
    throw new GeminiSafetyError([]);
  }
  
  throw new GeminiError('Gemini API è°ƒç”¨å¤±è´¥', error);
}
```

### é‡è¯•åŒ…è£…å™¨

```typescript
// src/services/ai/retry.ts
import { GeminiError, GeminiRateLimitError, handleGeminiError } from './errors';

interface RetryOptions {
  maxRetries?: number;
  baseDelay?: number;
  maxDelay?: number;
}

export async function withGeminiRetry<T>(
  fn: () => Promise<T>,
  options: RetryOptions = {}
): Promise<T> {
  const { maxRetries = 3, baseDelay = 1000, maxDelay = 30000 } = options;
  
  let lastError: Error | undefined;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      try {
        handleGeminiError(error);
      } catch (geminiError) {
        lastError = geminiError as Error;
        
        // ä¸é‡è¯•çš„é”™è¯¯
        if (
          !(geminiError instanceof GeminiRateLimitError) &&
          attempt === maxRetries
        ) {
          throw geminiError;
        }
        
        // è®¡ç®—å»¶è¿Ÿ
        const delay = Math.min(baseDelay * Math.pow(2, attempt), maxDelay);
        console.log(`[Gemini] é‡è¯• ${attempt + 1}/${maxRetries}ï¼Œç­‰å¾… ${delay}ms`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
  
  throw lastError;
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### è¯·æ±‚ç¼“å­˜

```typescript
// src/services/ai/cache.ts

const cache = new Map<string, { result: string; timestamp: number }>();
const CACHE_TTL = 5 * 60 * 1000; // 5 åˆ†é’Ÿ

/**
 * å¸¦ç¼“å­˜çš„ç”Ÿæˆ
 */
export async function generateWithCache(
  prompt: string,
  generator: (prompt: string) => Promise<string>
): Promise<string> {
  const cacheKey = hashPrompt(prompt);
  const cached = cache.get(cacheKey);
  
  if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
    console.log('[Gemini] å‘½ä¸­ç¼“å­˜');
    return cached.result;
  }
  
  const result = await generator(prompt);
  cache.set(cacheKey, { result, timestamp: Date.now() });
  
  return result;
}

function hashPrompt(prompt: string): string {
  // ç®€å•å“ˆå¸Œï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ›´å¥½çš„å“ˆå¸Œç®—æ³•
  let hash = 0;
  for (let i = 0; i < prompt.length; i++) {
    const char = prompt.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash;
  }
  return hash.toString(36);
}
```

### å¹¶å‘æ§åˆ¶

```typescript
// src/services/ai/concurrency.ts

class ConcurrencyLimiter {
  private running = 0;
  private queue: Array<() => void> = [];
  
  constructor(private maxConcurrent: number) {}
  
  async run<T>(fn: () => Promise<T>): Promise<T> {
    if (this.running >= this.maxConcurrent) {
      await new Promise<void>(resolve => this.queue.push(resolve));
    }
    
    this.running++;
    
    try {
      return await fn();
    } finally {
      this.running--;
      const next = this.queue.shift();
      if (next) next();
    }
  }
}

// é™åˆ¶å¹¶å‘è¯·æ±‚æ•°
export const geminiLimiter = new ConcurrencyLimiter(5);

// ä½¿ç”¨
const result = await geminiLimiter.run(() => generateText(prompt));
```

---

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

| åšæ³• | è¯´æ˜ |
|------|------|
| ä½¿ç”¨æµå¼å“åº” | é•¿æ–‡æœ¬ç”Ÿæˆæå‡ç”¨æˆ·ä½“éªŒ |
| ç»“æ„åŒ–æç¤ºè¯ | ä½¿ç”¨æ¨¡æ¿ç¡®ä¿è¾“å‡ºä¸€è‡´æ€§ |
| é”™è¯¯é‡è¯• | å¤„ç†ä¸´æ—¶æ€§ API é”™è¯¯ |
| è¯·æ±‚ç¼“å­˜ | ç›¸åŒè¯·æ±‚é¿å…é‡å¤è°ƒç”¨ |
| å¹¶å‘æ§åˆ¶ | é¿å…è§¦å‘é€Ÿç‡é™åˆ¶ |
| å®‰å…¨è¿‡æ»¤ | é…ç½®é€‚å½“çš„å®‰å…¨çº§åˆ« |

### âŒ é¿å…åšæ³•

| åšæ³• | é—®é¢˜ |
|------|------|
| å‰ç«¯ç›´æ¥è°ƒç”¨ API | æš´éœ² API Key |
| å¿½ç•¥é”™è¯¯å¤„ç† | ç”¨æˆ·ä½“éªŒå·® |
| æ— é™åˆ¶å¹¶å‘ | è§¦å‘é€Ÿç‡é™åˆ¶ |
| ç¡¬ç¼–ç æç¤ºè¯ | éš¾ä»¥ç»´æŠ¤å’Œä¼˜åŒ– |
| å¿½ç•¥ Token é™åˆ¶ | è¯·æ±‚å¤±è´¥æˆ–æˆªæ–­ |

---

## References

- `references/prompt-templates.md`: é‡‘èåˆ†ææç¤ºè¯æ¨¡æ¿ã€å¤šè½®å¯¹è¯æ¨¡æ¿

---

## Maintenance

- **Sources**: Google Gemini API å®˜æ–¹æ–‡æ¡£, é¡¹ç›®å®è·µç»éªŒ
- **Last Updated**: 2025-01-01
- **Known Limits**: 
  - API é€Ÿç‡é™åˆ¶éœ€æ ¹æ®è´¦æˆ·çº§åˆ«è°ƒæ•´
  - å¤šæ¨¡æ€åŠŸèƒ½éœ€è¦ Pro æ¨¡å‹
  - é•¿ä¸Šä¸‹æ–‡åœºæ™¯æˆæœ¬è¾ƒé«˜
