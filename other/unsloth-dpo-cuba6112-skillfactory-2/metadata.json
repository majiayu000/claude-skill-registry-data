{
  "name": "unsloth-dpo",
  "description": "Direct Preference Optimization (DPO) in Unsloth provides a way to align models with human preferences using paired data (chosen/rejected). Unsloth optimizes this process by allowing refmodel=None, sig",
  "repo": "cuba6112/skillfactory",
  "path": "skills/unsloth-dpo",
  "category": "other",
  "tags": [],
  "stars": 0,
  "source": "github.com/cuba6112/skillfactory",
  "dir_name": "unsloth-dpo-cuba6112-skillfactory-2"
}