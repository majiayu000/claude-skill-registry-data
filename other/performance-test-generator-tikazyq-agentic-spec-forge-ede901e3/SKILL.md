---
name: performance-test-generator
description: 基于NFR性能要求，生成性能测试场景和关键性能指标（KPI）。L3级别专用，当性能需求明确后使用。
stage: IMPLEMENTATION_PLANNING
level_supported: [L3]
---

## performance-test-generator: 性能测试生成器

### 描述
基于CRAFT L3的NFR性能要求，生成性能测试场景、性能指标定义和验收条件。确保应用性能达到需求。

### 适用场景
- **WORKFLOW_STEP_5 Task S5-2**: 创建test_suites.md中的性能测试章节（L3专用）
- **WORKFLOW_STEP_5 Task S5-3**: Self-Reflection分析性能测试覆盖
- **L3项目**: 有明确性能需求的系统（响应时间、吞吐量、并发等）

### 输入
- requirements/（特别是NFR中的性能需求）
- goal_breakdown.md（关键业务GOAL）
- design/architecture.md（架构设计，含可扩展性考虑）
- design/technology.md（技术栈，数据库/缓存等性能相关）
- 业务量预测（日活用户/并发数/数据量等）

### 输出
- 性能测试计划报告（markdown）
- KPI定义（响应时间/吞吐量/并发数/资源使用等）
- 性能测试场景（Given-When-Then格式）
- 性能验收条件（P99响应时间≤200ms等）
- 测试工具建议（JMeter/Gatling/LoadRunner等）

### 执行策略

**第1步: 提取性能NFR**
从requirements/NFR中识别性能需求，分类为：
- 响应时间: P50/P95/P99百分位数（如P99<200ms）
- 吞吐量: QPS/TPS（如1000 QPS）
- 并发: 最大并发用户数（如10000并发）
- 资源: CPU/内存/磁盘使用限制
- 可用性: 可用性要求（如99.9%）

**第2步: 性能指标映射**
根据应用类型定义关键KPI：
| 应用类型 | 关键指标 | 基准值 | 压力值 |
|---------|--------|-------|-------|
| Web应用 | 页面加载时间 | <1s | <3s |
| API | 响应时间(P99) | <200ms | <500ms |
| 数据库 | 查询时间 | <100ms | <300ms |
| 缓存 | 命中率 | >90% | >80% |

**第3步: 业务量预测**
根据需求确定测试规模：
- 日活用户(DAU) → 并发用户数 = DAU × 峰值系数 / 3600
- 业务操作 → QPS = 日操作数 / 86400 × 峰值系数
- 数据量 → 存储/查询性能影响

**第4步: 关键路径KPI定义**
为核心业务流程定义KPI：
- 登录: P99响应时间 ≤ 500ms
- 查询: P99响应时间 ≤ 200ms
- 下单: P99响应时间 ≤ 1000ms
- 支付: P99响应时间 ≤ 2000ms

**第5步: 性能测试场景**
- 基准测试: 正常负载（50%峰值）
- 压力测试: 突增负载（100%峰值）
- 耐久性测试: 长时间运行（8小时）
- 尖峰测试: 瞬间峰值（150%峰值）

**第6步: L1/L2/L3分级**
- **L1**: 仅基准测试，关键路径KPI
- **L2**: 基准+压力测试，主要路径KPI
- **L3**: 完整测试（基准/压力/耐久/尖峰），所有路径KPI

**第7步: 测试工具选择**
| 工具 | 适用场景 | 特点 |
|------|--------|------|
| JMeter | 通用性能测试 | 开源、支持多协议 |
| Gatling | API性能测试 | 高吞吐、实时报告 |
| LoadRunner | 企业级测试 | 功能完整、成本高 |
| Locust | Python脚本测试 | 灵活、易扩展 |

### 价值
- **SPEC组织**: 将性能需求转化为可量化的测试目标
- **DevOps/QA**: 系统化的性能测试覆盖和持续监控
- **Dev**: 明确的性能约束，指导优化方向

### 验收标准（L3）
- 覆盖所有NFR性能要求
- 关键路径KPI明确定义
- 给定-当-那 格式清晰规范
- 验收条件可量化可自动化
- 包含基准/压力/耐久性测试
