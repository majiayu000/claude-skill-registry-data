---
name: plan-mode-official-leaderboard-abctest
description: å…¬å¼ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰æº–æ‹ ã®A/B/Cãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹Planãƒ¢ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ«ã€‚Phi-3.5-mini-instructã€Borea-phi3.5-instinct-jpã€AEGIS-Phi3.5mini-jpv2.4ã‚’æ¨™æº–åŒ–ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã§æ¯”è¼ƒè©•ä¾¡ã—ã€çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã€‚
metadata:
  short-description: å…¬å¼æº–æ‹ A/B/Cãƒ†ã‚¹ãƒˆPlanãƒ¢ãƒ¼ãƒ‰
  version: 1.0.0
  author: SO8T Assistant
  capabilities:
    - official_benchmark_evaluation
    - statistical_ab_testing
    - model_comparison_analysis
    - leaderboard_compliance
---

# Planãƒ¢ãƒ¼ãƒ‰å…¬å¼ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰æº–æ‹ A/B/Cãƒ†ã‚¹ãƒˆã‚¹ã‚­ãƒ«

SO8Tãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå°‚ç”¨ã«è¨­è¨ˆã•ã‚ŒãŸå…¬å¼ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰æº–æ‹ ã®A/B/Cãƒ†ã‚¹ãƒˆå®Ÿè¡ŒPlanãƒ¢ãƒ¼ãƒ‰ã€‚Phi-3.5-mini-instructã€Borea-phi3.5-instinct-jpã€AEGIS-Phi3.5mini-jp v2.4ã®3ãƒ¢ãƒ‡ãƒ«ã‚’GSM8K/MATH/ARC-Challengeã§æ¨™æº–åŒ–è©•ä¾¡ã—ã€çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚

## ðŸš€ ä¸»è¦æ©Ÿèƒ½

### 1. å…¬å¼æº–æ‹ ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯è©•ä¾¡
- **GSM8K**: 8-shot CoT (Phi-3.5å…¬å¼: 86.2%)
- **MATH**: 0-shot CoT (Phi-3.5å…¬å¼: 48.5%)
- **ARC-Challenge**: 10-shot (Phi-3.5å…¬å¼: 84.6%)
- **ãƒ—ãƒ­ãƒˆã‚³ãƒ«åŽ³å®ˆ**: å…¬å¼è©•ä¾¡ãƒãƒ¼ãƒã‚¹ä½¿ç”¨

### 2. çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼
- **t-test**: ãƒ¢ãƒ‡ãƒ«é–“å·®ã®çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
- **åŠ¹æžœã‚µã‚¤ã‚º**: Cohen's dã«ã‚ˆã‚‹åŠ¹æžœã®å¤§ãã•è©•ä¾¡
- **ä¿¡é ¼åŒºé–“**: 95%ä¿¡é ¼åŒºé–“ã§ã®çµæžœæç¤º
- **å¤šé‡æ¯”è¼ƒè£œæ­£**: Bonferroniæ³•ç­‰ã«ã‚ˆã‚‹èª¿æ•´

### 3. A/B/Cãƒ†ã‚¹ãƒˆå®Ÿè¡Œç®¡ç†
- **ä¸¦è¡Œè©•ä¾¡**: 3ãƒ¢ãƒ‡ãƒ«åŒæ™‚è©•ä¾¡ã§åŠ¹çŽ‡åŒ–
- **ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**: å®‰å®šæ€§ç¢ºä¿ã®ãŸã‚ã®è¤‡æ•°å›žå®Ÿè¡Œ
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: è©•ä¾¡å¤±æ•—æ™‚ã®è‡ªå‹•ãƒªã‚«ãƒãƒªãƒ¼
- **çµæžœé›†ç´„**: åŒ…æ‹¬çš„ãªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

### 4. SO8Tçµ±åˆæœ€é©åŒ–
- **Enhanced Moonshotçµ±åˆ**: æ—¢å­˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã®é€£æº
- **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†**: é•·æ™‚é–“è©•ä¾¡ã®ä¸­æ–­å¾©æ—§
- **ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–**: GPUä½¿ç”¨ã®åŠ¹çŽ‡çš„æœ€é©åŒ–
- **ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ**: è«–æ–‡ãƒ¬ãƒ™ãƒ«ã®æ¯”è¼ƒåˆ†æž

## ðŸ“‹ ä½¿ç”¨ä¾‹

### å…¬å¼æº–æ‹ A/B/Cãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
```python
from skills.plan_mode_official_leaderboard_abctest import OfficialABCTestPlan

# 3ãƒ¢ãƒ‡ãƒ«å…¬å¼æº–æ‹ æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
abc_test = OfficialABCTestPlan()

test_config = {
    "models": {
        "Phi-3.5-mini-instruct": "microsoft/Phi-3.5-mini-instruct",
        "Borea-phi3.5-instinct-jp": "path/to/borea/model",
        "AEGIS-Phi3.5mini-jp-v2.4": "your-username/AEGIS-Phi3.5mini-jp"
    },
    "benchmarks": ["gsm8k", "math", "arc_challenge"],
    "sample_sizes": {"gsm8k": 1000, "math": 500, "arc_challenge": 1000},
    "runs_per_model": 3,  # çµ±è¨ˆçš„å®‰å®šæ€§ã®ãŸã‚ã®è¤‡æ•°å›žå®Ÿè¡Œ
    "statistical_tests": ["t_test", "cohen_d", "confidence_intervals"],
    "significance_level": 0.05
}

# å…¬å¼æº–æ‹ A/B/Cãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
results = abc_test.execute_official_abctest(test_config)
print(f"A/B/C Test completed: {results['summary']['winner']}")
```

### çµ±è¨ˆçš„æ¤œè¨¼ä»˜ãè©•ä¾¡
```python
# è©³ç´°ãªçµ±è¨ˆåˆ†æžã‚’å«ã‚€è©•ä¾¡
statistical_analysis = abc_test.perform_statistical_analysis(results)

print("=== STATISTICAL SIGNIFICANCE RESULTS ===")
for benchmark in results['benchmarks']:
    print(f"{benchmark.upper()}:")
    for comparison in results['comparisons'][benchmark]:
        print(f"  {comparison['model_a']} vs {comparison['model_b']}:")
        print(f"    t-statistic: {comparison['t_statistic']:.3f}")
        print(f"    p-value: {comparison['p_value']:.4f}")
        print(f"    Cohen's d: {comparison['cohen_d']:.3f}")
        print(f"    Significant: {'Yes' if comparison['significant'] else 'No'}")
```

### çµæžœå¯è¦–åŒ–ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
```python
# æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
visualization = abc_test.generate_comparison_visualization(results)
report = abc_test.generate_official_report(results)

# ä¿å­˜
abc_test.save_results(results, "official_abctest_results.json")
abc_test.save_visualizations(visualization, "charts/")
abc_test.save_report(report, "reports/official_abctest_report.pdf")
```

## ðŸ—ï¸ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### ãƒ•ã‚§ãƒ¼ã‚º1: ç’°å¢ƒæº–å‚™ã¨æ¤œè¨¼
```python
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã¨åŸºæœ¬æ¤œè¨¼
models_ready = abc_test.verify_models_availability(test_config['models'])
benchmarks_ready = abc_test.verify_benchmarks_availability(test_config['benchmarks'])

if not (models_ready and benchmarks_ready):
    raise ValueError("Models or benchmarks not available")

# ãƒªã‚½ãƒ¼ã‚¹å‰²ã‚Šå½“ã¦æœ€é©åŒ–
resource_plan = abc_test.optimize_resource_allocation(test_config)
print(f"GPU allocation: {resource_plan['gpu_allocation']}")
print(f"Estimated time: {resource_plan['estimated_hours']} hours")
```

### ãƒ•ã‚§ãƒ¼ã‚º2: ä¸¦è¡Œè©•ä¾¡å®Ÿè¡Œ
```python
# è¤‡æ•°GPUã§ã®ä¸¦è¡Œè©•ä¾¡
evaluation_jobs = abc_test.create_evaluation_jobs(test_config)
results = abc_test.execute_parallel_evaluations(evaluation_jobs)

# é€²æ—ç›£è¦–
with tqdm(total=len(evaluation_jobs), desc="A/B/C Test Progress") as pbar:
    for completed_job in abc_test.monitor_evaluation_progress():
        pbar.update(1)
        print(f"Completed: {completed_job['model']} on {completed_job['benchmark']}")
```

### ãƒ•ã‚§ãƒ¼ã‚º3: çµ±è¨ˆåˆ†æžã¨æ¤œè¨¼
```python
# çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
statistical_tests = abc_test.perform_statistical_tests(results, test_config['significance_level'])

# åŠ¹æžœã‚µã‚¤ã‚ºè¨ˆç®—
effect_sizes = abc_test.calculate_effect_sizes(results)

# ä¿¡é ¼åŒºé–“æŽ¨å®š
confidence_intervals = abc_test.calculate_confidence_intervals(results, confidence_level=0.95)

# å¤šé‡æ¯”è¼ƒè£œæ­£
corrected_p_values = abc_test.apply_multiple_comparison_correction(statistical_tests)
```

### ãƒ•ã‚§ãƒ¼ã‚º4: çµæžœçµ±åˆã¨ãƒ¬ãƒãƒ¼ãƒˆ
```python
# çµæžœé›†ç´„
final_results = abc_test.aggregate_results(results, statistical_tests, effect_sizes)

# å‹è€…æ±ºå®šï¼ˆçµ±è¨ˆçš„æœ‰æ„æ€§ãƒ™ãƒ¼ã‚¹ï¼‰
winner_analysis = abc_test.determine_winner(final_results, test_config)

# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
comprehensive_report = abc_test.generate_comprehensive_report(final_results, winner_analysis)
```

## ðŸ”¬ çµ±è¨ˆçš„æ–¹æ³•è«–

### A/B/Cãƒ†ã‚¹ãƒˆè¨­è¨ˆ
```python
class ABCTestDesign:
    def __init__(self, models, benchmarks, significance_level=0.05):
        self.models = models  # 3ã¤ã®ãƒ¢ãƒ‡ãƒ«
        self.benchmarks = benchmarks
        self.alpha = significance_level
        self.adjusted_alpha = self.alpha / 3  # Bonferroniè£œæ­£

    def calculate_required_sample_size(self, effect_size, power=0.8):
        """å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—"""
        # Cohen's dã«åŸºã¥ãpower analysis
        return self.power_analysis_sample_size(effect_size, power)

    def create_comparison_matrix(self):
        """3ãƒ¢ãƒ‡ãƒ«é–“ã®å…¨æ¯”è¼ƒãƒšã‚¢ç”Ÿæˆ"""
        return [
            (model_a, model_b)
            for i, model_a in enumerate(self.models[:-1])
            for model_b in self.models[i+1:]
        ]
```

### çµ±è¨ˆçš„æ¤œå®šå®Ÿè£…
```python
class StatisticalTester:
    def perform_pairwise_t_tests(self, results_a, results_b):
        """å¯¾å¿œã®ãªã„t-testå®Ÿè¡Œ"""
        from scipy.stats import ttest_ind

        t_stat, p_value = ttest_ind(results_a, results_b, equal_var=False)

        # Cohen's dåŠ¹æžœã‚µã‚¤ã‚º
        mean_diff = np.mean(results_a) - np.mean(results_b)
        pooled_std = np.sqrt((np.std(results_a)**2 + np.std(results_b)**2) / 2)
        cohen_d = mean_diff / pooled_std if pooled_std > 0 else 0

        return {
            't_statistic': t_stat,
            'p_value': p_value,
            'cohen_d': cohen_d,
            'significant': p_value < self.adjusted_alpha,
            'effect_size_interpretation': self.interpret_cohen_d(cohen_d)
        }

    def interpret_cohen_d(self, d):
        """Cohen's dã®è§£é‡ˆ"""
        abs_d = abs(d)
        if abs_d < 0.2:
            return "negligible"
        elif abs_d < 0.5:
            return "small"
        elif abs_d < 0.8:
            return "medium"
        else:
            return "large"
```

### ä¿¡é ¼åŒºé–“è¨ˆç®—
```python
class ConfidenceIntervalCalculator:
    def calculate_bootstrap_ci(self, data, n_bootstrap=1000, ci_level=0.95):
        """ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ³•ã«ã‚ˆã‚‹ä¿¡é ¼åŒºé–“"""
        bootstrap_means = []
        n = len(data)

        for _ in range(n_bootstrap):
            sample = np.random.choice(data, size=n, replace=True)
            bootstrap_means.append(np.mean(sample))

        lower_percentile = (1 - ci_level) / 2 * 100
        upper_percentile = (1 + ci_level) / 2 * 100

        return {
            'mean': np.mean(data),
            'ci_lower': np.percentile(bootstrap_means, lower_percentile),
            'ci_upper': np.percentile(bootstrap_means, upper_percentile),
            'ci_level': ci_level
        }
```

## ðŸ“Š è©•ä¾¡çµæžœæ§‹é€ 

### çµæžœãƒ‡ãƒ¼ã‚¿æ§‹é€ 
```python
OfficialABCTestResults = {
    'metadata': {
        'timestamp': '2026-01-17 03:00:00',
        'models_tested': ['Phi-3.5-mini-instruct', 'Borea-phi3.5-instinct-jp', 'AEGIS-Phi3.5mini-jp-v2.4'],
        'benchmarks': ['gsm8k', 'math', 'arc_challenge'],
        'sample_sizes': {'gsm8k': 1000, 'math': 500, 'arc_challenge': 1000},
        'runs_per_model': 3,
        'evaluation_protocols': {
            'gsm8k': '8-shot CoT',
            'math': '0-shot CoT',
            'arc_challenge': '10-shot'
        }
    },
    'raw_results': {
        'model_name': {
            'benchmark_name': {
                'run_1': {'accuracy': 0.xxx, 'individual_scores': [...]},
                'run_2': {...},
                'run_3': {...},
                'aggregate': {'mean': 0.xxx, 'std': 0.xxx, '95ci': [0.xxx, 0.xxx]}
            }
        }
    },
    'statistical_analysis': {
        'pairwise_comparisons': [
            {
                'model_a': 'AEGIS-Phi3.5mini-jp-v2.4',
                'model_b': 'Phi-3.5-mini-instruct',
                'benchmark': 'gsm8k',
                't_statistic': 2.345,
                'p_value': 0.023,
                'cohen_d': 0.678,
                'significant': True,
                'effect_size': 'medium',
                'confidence_intervals': {'model_a': [0.85, 0.87], 'model_b': [0.83, 0.85]}
            }
        ],
        'overall_rankings': {
            'gsm8k': ['AEGIS-Phi3.5mini-jp-v2.4', 'Borea-phi3.5-instinct-jp', 'Phi-3.5-mini-instruct'],
            'math': ['AEGIS-Phi3.5mini-jp-v2.4', 'Phi-3.5-mini-instruct', 'Borea-phi3.5-instinct-jp'],
            'arc_challenge': ['Phi-3.5-mini-instruct', 'AEGIS-Phi3.5mini-jp-v2.4', 'Borea-phi3.5-instinct-jp']
        }
    },
    'summary': {
        'winner_by_benchmark': {
            'gsm8k': 'AEGIS-Phi3.5mini-jp-v2.4',
            'math': 'AEGIS-Phi3.5mini-jp-v2.4',
            'arc_challenge': 'Phi-3.5-mini-instruct'
        },
        'overall_winner': 'AEGIS-Phi3.5mini-jp-v2.4',
        'confidence_level': 'high',
        'key_findings': [
            'AEGIS shows significant improvement in GSM8K and MATH',
            'Phi-3.5-mini-instruct performs best on ARC-Challenge',
            'All differences are statistically significant (p < 0.05)'
        ]
    }
}
```

## ðŸŽ¯ å®Ÿè¡Œä¾‹ã¨ã‚³ãƒžãƒ³ãƒ‰

### åŸºæœ¬å®Ÿè¡Œã‚³ãƒžãƒ³ãƒ‰
```bash
# å…¬å¼æº–æ‹ A/B/Cãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python scripts/plan_mode_official_abctest.py \
  --models-config scripts/evaluation/models_config.json \
  --benchmarks gsm8k math arc_challenge \
  --sample-sizes "gsm8k:1000,math:500,arc_challenge:1000" \
  --runs-per-model 3 \
  --significance-level 0.05 \
  --output-dir evaluation_results/official_abctest/
```

### çµæžœåˆ†æžã‚³ãƒžãƒ³ãƒ‰
```bash
# çµ±è¨ˆåˆ†æžã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
python scripts/analyze_abctest_results.py \
  --results-dir evaluation_results/official_abctest/ \
  --generate-plots \
  --create-pdf-report \
  --significance-analysis
```

### æ¯”è¼ƒå¯è¦–åŒ–ã‚³ãƒžãƒ³ãƒ‰
```bash
# çµæžœæ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ
python scripts/visualize_abctest_comparison.py \
  --results-file evaluation_results/official_abctest/final_results.json \
  --output-dir charts/abctest_comparison/ \
  --chart-types "bar,ranking,effect_size,confidence_intervals"
```

## ðŸ”§ æŠ€è¡“ä»•æ§˜

### ä¾å­˜é–¢ä¿‚
- **transformers**: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã¨æŽ¨è«–
- **scipy**: çµ±è¨ˆçš„æ¤œå®š (t-test, åŠ¹æžœã‚µã‚¤ã‚º)
- **numpy**: æ•°å€¤è¨ˆç®—ã¨ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—
- **matplotlib/seaborn**: çµæžœå¯è¦–åŒ–
- **pandas**: ãƒ‡ãƒ¼ã‚¿é›†è¨ˆã¨åˆ†æž
- **tqdm**: é€²æ—è¡¨ç¤º
- **concurrent.futures**: ä¸¦è¡Œè©•ä¾¡å®Ÿè¡Œ

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æœ€é©åŒ–
- **GPUä¸¦è¡Œå‡¦ç†**: è¤‡æ•°GPUã§ã®åŒæ™‚è©•ä¾¡
- **ãƒ¡ãƒ¢ãƒªåŠ¹çŽ‡åŒ–**: ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›
- **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ**: é•·æ™‚é–“è©•ä¾¡ã®ä¸­æ–­å¾©æ—§
- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: ç¹°ã‚Šè¿”ã—è©•ä¾¡ã®é«˜é€ŸåŒ–

### å“è³ªä¿è¨¼
- **ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**: çµæžœã®å®‰å®šæ€§æ¤œè¨¼
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: è©•ä¾¡å¤±æ•—æ™‚ã®é©åˆ‡ãªå‡¦ç†
- **ãƒ­ã‚°è¨˜éŒ²**: è©³ç´°ãªå®Ÿè¡Œãƒ­ã‚°ã®ä¿å­˜
- **å†ç¾æ€§**: ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šã«ã‚ˆã‚‹å†ç¾æ€§ç¢ºä¿

## ðŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹æˆæžœ

### çµ±è¨ˆçš„æœ‰æ„æ€§ã®ã‚ã‚‹æ¯”è¼ƒ
- **å‹è€…æ±ºå®š**: å„ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã§ã®çµ±è¨ˆçš„æœ‰æ„ãªå„ªä½æ€§
- **åŠ¹æžœã‚µã‚¤ã‚º**: å®Ÿç”¨çš„æ„ç¾©ã®ã‚ã‚‹æ”¹å–„é‡ã®è©•ä¾¡
- **ä¿¡é ¼åŒºé–“**: çµæžœã®ä¸ç¢ºå®Ÿæ€§ç¯„å›²ã®æç¤º

### åŒ…æ‹¬çš„ãªåˆ†æžãƒ¬ãƒãƒ¼ãƒˆ
- **å®Ÿè¡Œã‚µãƒžãƒªãƒ¼**: ãƒ†ã‚¹ãƒˆæ¡ä»¶ã¨å®Ÿè¡Œçµæžœã®æ¦‚è¦
- **è©³ç´°æ¯”è¼ƒ**: ãƒ¢ãƒ‡ãƒ«é–“ã®çµ±è¨ˆçš„æœ‰æ„ãªå·®ç•°
- **å¯è¦–åŒ–**: æ¯”è¼ƒã‚’ç›´æ„Ÿçš„ã«ç†è§£ã§ãã‚‹ãƒãƒ£ãƒ¼ãƒˆ
- **æŽ¨å¥¨**: å„ãƒ¢ãƒ‡ãƒ«ã®é©ã—ãŸä½¿ç”¨å ´é¢

## âœ… å®Ÿè£…å®Œäº†ç¢ºèª

- âœ… **Planãƒ¢ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ«ä½œæˆ**: å…¬å¼æº–æ‹ A/B/Cãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- âœ… **3ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè¨­å®š**: Phi-3.5ã€Boreaã€AEGISã®åŒæ™‚è©•ä¾¡
- âœ… **çµ±è¨ˆçš„æ¤œè¨¼æ©Ÿèƒ½**: t-testã€åŠ¹æžœã‚µã‚¤ã‚ºã€ä¿¡é ¼åŒºé–“
- âœ… **çµæžœçµ±åˆã‚·ã‚¹ãƒ†ãƒ **: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- âœ… **SO8Tçµ±åˆ**: æ—¢å­˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã®é€£æº

**ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ãƒ‡ãƒ«:** 3ãƒ¢ãƒ‡ãƒ« (Phi-3.5-mini-instruct, Borea-phi3.5-instinct-jp, AEGIS-Phi3.5mini-jp-v2.4)  
**è©•ä¾¡ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯:** 3ç¨®é¡ž (GSM8K, MATH, ARC-Challenge)  
**çµ±è¨ˆçš„åŽ³å¯†æ€§:** å…¬å¼ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰æº–æ‹  + çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œè¨¼  

---

*ã“ã®Planãƒ¢ãƒ¼ãƒ‰ã¯ã€SO8Tãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹å…¬å¼æº–æ‹ ã®ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè©•ä¾¡ã‚’å®Œå…¨ã«è‡ªå‹•åŒ–ã—ã€çµ±è¨ˆçš„ã«ä¿¡é ¼ã§ãã‚‹A/B/Cãƒ†ã‚¹ãƒˆçµæžœã‚’æä¾›ã—ã¾ã™ã€‚*