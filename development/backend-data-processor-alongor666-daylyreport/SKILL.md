---
name: backend-data-processor
description: Process vehicle insurance Excel data using Pandas - file handling, data cleaning, merging, validation. Use when processing Excel/CSV files, handling data imports, implementing business rules (negative premiums, zero commissions), debugging data pipelines, or optimizing Pandas performance. Keywords: data_processor.py, Excel, CSV, Pandas, merge, deduplication, date normalization.
allowed-tools: Read, Edit, Grep, Glob
---

# Backend Data Processor - è½¦é™©æ•°æ®å¤„ç†åç«¯å®ç°æŒ‡å—

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-08
**é€‚ç”¨åœºæ™¯**: Excel æ•°æ®å¤„ç†ã€æ•°æ®æ¸…æ´—ã€æ–‡ä»¶åˆå¹¶ã€æ•°æ®éªŒè¯

---

## ğŸ“Œ Skill æ¦‚è¿°

æœ¬ Skill æä¾›è½¦é™©ç­¾å•æ•°æ®å¤„ç†åç«¯çš„å®Œæ•´å®ç°æŒ‡å—,ä½œä¸º `analyzing-auto-insurance-data` Skill çš„åç«¯è¡¥å……ã€‚æ¶µç›–æ•°æ®æµè½¬ã€æ ¸å¿ƒå¤„ç†é€»è¾‘ã€ä¸šåŠ¡è§„åˆ™å®ç°ã€æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†ã€‚

**æ ¸å¿ƒä»·å€¼**:
- âœ… **æ•°æ®æµè½¬æ¶æ„**: Excel â†’ CSV â†’ åˆå¹¶ â†’ å­˜å‚¨å…¨æµç¨‹
- âœ… **æ ¸å¿ƒå¤„ç†å‡½æ•°**: 4ä¸ªå…³é”®æ–¹æ³•è¯¦è§£(æ–‡ä»¶å¤„ç†/æ¸…æ´—/åˆå¹¶/æ‰¹é‡æ‰«æ)
- âœ… **ä¸šåŠ¡è§„åˆ™å®ç°**: è´Ÿä¿è´¹/é›¶æ‰‹ç»­è´¹/æ—¥æœŸæ ‡å‡†åŒ–/ç¼ºå¤±å€¼å¡«å……
- âœ… **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**: Pandas æœ€ä½³å®è·µã€å†…å­˜ç®¡ç†ã€å¤§æ–‡ä»¶å¤„ç†
- âœ… **é”™è¯¯å¤„ç†ä¸æ—¥å¿—**: å¼‚å¸¸æ•è·æœºåˆ¶ã€æ—¥å¿—æ ‡å‡†ã€ç”¨æˆ·å‹å¥½æç¤º

**å…³é”®æ–‡ä»¶ä½ç½®**:
- [backend/data_processor.py](../../backend/data_processor.py) - æ•°æ®å¤„ç†æ ¸å¿ƒ
- [backend/api_server.py](../../backend/api_server.py) - Flask API æœåŠ¡

---

## ğŸ“Š ä¸€ã€æ•°æ®æµè½¬æ¶æ„

### 1.1 æ•´ä½“æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Excel æ–‡ä»¶ä¸Šä¼ åˆ° data/ ç›®å½•                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  scan_and_process_new_files()                                   â”‚
â”‚  - æ‰«æ data/*.xlsx, data/*.xls                                  â”‚
â”‚  - æ‰¹é‡å¤„ç†æ‰€æœ‰æ–°æ–‡ä»¶                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  process_new_excel(excel_path)        â”‚
         â”‚  - è¯»å– Excel æ–‡ä»¶ (pd.read_excel)     â”‚
         â”‚  - è¿”å›åŸå§‹ DataFrame                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  _clean_data(df)                      â”‚
         â”‚  - åˆ é™¤ç©ºè¡Œ                            â”‚
         â”‚  - æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ–                       â”‚
         â”‚  - æ•°å€¼ç±»å‹è½¬æ¢                         â”‚
         â”‚  - ç¼ºå¤±å€¼å¡«å……ä¸ºç©ºå­—ç¬¦ä¸²                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  merge_with_existing(new_df)          â”‚
         â”‚  - è¯»å–ç°æœ‰ CSV (å¦‚å­˜åœ¨)                â”‚
         â”‚  - pd.concat() åˆå¹¶æ–°æ—§æ•°æ®             â”‚
         â”‚  - æ ¹æ®ä¿å•å·+æŠ•ä¿ç¡®è®¤æ—¶é—´å»é‡           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  save_merged_data(df)                 â”‚
         â”‚  - ä¿å­˜ä¸º è½¦é™©æ¸…å•_2025å¹´10-11æœˆ_åˆå¹¶.csv â”‚
         â”‚  - ç¼–ç : utf-8-sig (æ”¯æŒExcelæ‰“å¼€)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ç§»åŠ¨åˆ° data/processed/ ç›®å½•            â”‚
         â”‚  - é‡å‘½å: åŸæ–‡ä»¶å_processed_æ—¶é—´æˆ³.xlsx â”‚
         â”‚  - é¿å…é‡å¤å¤„ç†                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ–‡ä»¶å‘½åä¸ç‰ˆæœ¬ç®¡ç†

**è¾“å…¥æ–‡ä»¶å‘½åè§„èŒƒ**:
- æ ¼å¼: `data/*.xlsx` æˆ– `data/*.xls`
- ç¤ºä¾‹: `è½¦é™©æ¸…å•_2025å¹´10æœˆ.xlsx`

**å¤„ç†åæ–‡ä»¶å‘½å**:
- æ ¼å¼: `data/processed/{åŸæ–‡ä»¶å}_processed_{YYYYMMDD_HHMMSS}.xlsx`
- ç¤ºä¾‹: `data/processed/è½¦é™©æ¸…å•_2025å¹´10æœˆ_processed_20251108_143025.xlsx`

**åˆå¹¶æ–‡ä»¶å‘½å**:
- å›ºå®šæ–‡ä»¶å: `è½¦é™©æ¸…å•_2025å¹´10-11æœˆ_åˆå¹¶.csv`
- ä½ç½®: é¡¹ç›®æ ¹ç›®å½•
- ç¼–ç : `utf-8-sig` (å¸¦ BOM,Excel å¯ç›´æ¥æ‰“å¼€)

### 1.3 å¢é‡æ›´æ–°ç­–ç•¥

**å»é‡é€»è¾‘** ([data_processor.py:172-177](../../backend/data_processor.py#L172-L177)):
```python
# æ ¹æ®ä¿å•å·å’ŒæŠ•ä¿ç¡®è®¤æ—¶é—´å»é‡,ä¿ç•™æœ€æ–°è®°å½•
merged_df = merged_df.drop_duplicates(
    subset=['ä¿å•å·', 'æŠ•ä¿ç¡®è®¤æ—¶é—´'],
    keep='last'
)
```

**ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸¤ä¸ªå­—æ®µ**:
- `ä¿å•å·`: ä¸šåŠ¡å”¯ä¸€æ ‡è¯†
- `æŠ•ä¿ç¡®è®¤æ—¶é—´`: åŒä¸€ä¿å•å¯èƒ½æœ‰æ‰¹æ”¹è®°å½•,éœ€è¦ä¿ç•™æ—¶é—´ç»´åº¦

**`keep='last'` çš„åŸå› **:
- æ‰¹æ”¹æ“ä½œä¼šæ›´æ–°ä¿å•ä¿¡æ¯,æœ€æ–°è®°å½•æ›´å‡†ç¡®
- åˆå¹¶æ—¶æ–°æ•°æ®åœ¨å,`keep='last'` ä¼˜å…ˆä¿ç•™æ–°æ•°æ®

---

## ğŸ”§ äºŒã€æ ¸å¿ƒå¤„ç†å‡½æ•°è¯¦è§£

### 2.1 `process_new_excel(excel_path)` - Excel æ–‡ä»¶å¤„ç†

**ä½ç½®**: [data_processor.py:107-127](../../backend/data_processor.py#L107-L127)

**åŠŸèƒ½**: è¯»å– Excel æ–‡ä»¶å¹¶è¿”å›æ¸…æ´—åçš„ DataFrame

**å®ç°ç»†èŠ‚**:
```python
def process_new_excel(self, excel_path):
    print(f"æ­£åœ¨å¤„ç†Excelæ–‡ä»¶: {excel_path}")

    # è¯»å– Excel æ–‡ä»¶
    df = pd.read_excel(excel_path)

    print(f"  è¯»å–æˆåŠŸ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")

    # æ•°æ®æ¸…æ´—
    df = self._clean_data(df)

    return df
```

**æ³¨æ„äº‹é¡¹**:
- âŒ **ä¸è¦ä½¿ç”¨** `pd.read_excel(excel_path, dtype=str)` - ä¼šå¯¼è‡´æ•°å€¼è®¡ç®—å¤±è´¥
- âœ… **æ¨è**: è®© Pandas è‡ªåŠ¨æ¨æ–­ç±»å‹,åç»­åœ¨ `_clean_data()` ä¸­è½¬æ¢
- âœ… **å¼‚å¸¸å¤„ç†**: è°ƒç”¨æ–¹ `scan_and_process_new_files()` å·²å¤„ç†å¼‚å¸¸

**å¸¸è§é—®é¢˜**:
1. **Excel æ–‡ä»¶æŸå**: ä¼šæŠ›å‡º `xlrd.biffh.XLRDError`
2. **æ–‡ä»¶è¢«å ç”¨**: Windows ä¸‹å¯èƒ½æŠ›å‡º `PermissionError`
3. **å†…å­˜ä¸è¶³**: å¤§æ–‡ä»¶(>100MB)å¯èƒ½è§¦å‘ `MemoryError`

---

### 2.2 `_clean_data(df)` - æ•°æ®æ¸…æ´—

**ä½ç½®**: [data_processor.py:129-153](../../backend/data_processor.py#L129-L153)

**åŠŸèƒ½**: æ ‡å‡†åŒ–æ•°æ®æ ¼å¼,ç¡®ä¿ç¬¦åˆ CSV è§„èŒƒ

**æ¸…æ´—æ­¥éª¤**:

#### æ­¥éª¤ 1: åˆ é™¤å®Œå…¨ä¸ºç©ºçš„è¡Œ
```python
df = df.dropna(how='all')
```
- ç§»é™¤ Excel ä¸­çš„ç©ºç™½è¡Œ
- é¿å…åç»­è®¡ç®—æ—¶å‡ºç° NaN å€¼æ±¡æŸ“

#### æ­¥éª¤ 2: æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ–
```python
date_columns = ['åˆ·æ–°æ—¶é—´', 'æŠ•ä¿ç¡®è®¤æ—¶é—´', 'ä¿é™©èµ·æœŸ']
for col in date_columns:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')
```
- `errors='coerce'`: æ— æ³•è§£æçš„æ—¥æœŸè½¬ä¸º `NaT` (Not a Time)
- æ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼: `2025-11-08`, `2025/11/08`, `20251108` ç­‰

**å¸¸è§æ—¥æœŸé—®é¢˜**:
- Excel æ—¥æœŸåºåˆ—å·: `44500` â†’ è‡ªåŠ¨è½¬æ¢ä¸º `2021-10-15`
- æ–‡æœ¬æ—¥æœŸ: `"2025å¹´11æœˆ8æ—¥"` â†’ `errors='coerce'` ä¼šè½¬ä¸º `NaT`
- ç©ºå€¼: ä¿ç•™ä¸º `NaT`,åç»­å¡«å……ä¸ºç©ºå­—ç¬¦ä¸²

#### æ­¥éª¤ 3: æ•°å€¼ç±»å‹è½¬æ¢
```python
numeric_columns = ['ç­¾å•/æ‰¹æ”¹ä¿è´¹', 'ç­¾å•æ•°é‡', 'æ‰‹ç»­è´¹', 'æ‰‹ç»­è´¹å«ç¨', 'å¢å€¼ç¨']
for col in numeric_columns:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
```
- `errors='coerce'`: æ— æ³•è§£æçš„æ•°å€¼è½¬ä¸º `NaN`
- è‡ªåŠ¨å¤„ç†: `"1,234.56"` â†’ `1234.56` (ç§»é™¤åƒåˆ†ä½é€—å·)

**å¸¸è§æ•°å€¼é—®é¢˜**:
- è´Ÿä¿è´¹: `-5000.00` (é€€ä¿/æ‰¹æ”¹) â†’ ä¿ç•™è´Ÿæ•°,ä¸åšä¿®æ”¹
- é›¶æ‰‹ç»­è´¹: `0.00` â†’ åˆæ³•å€¼,ä¸åšä¿®æ”¹
- æ–‡æœ¬æ•°å€¼: `"äº”ä¸‡"` â†’ è½¬ä¸º `NaN`

#### æ­¥éª¤ 4: ç¼ºå¤±å€¼å¡«å……
```python
df = df.fillna('')
```
- å°†æ‰€æœ‰ `NaN` / `NaT` å¡«å……ä¸ºç©ºå­—ç¬¦ä¸² `''`
- é¿å… JSON åºåˆ—åŒ–æ—¶å‡ºç° `null` å€¼
- å‰ç«¯å¯ç»Ÿä¸€åˆ¤æ–­ `value === ''` æ¥è¯†åˆ«ç¼ºå¤±

**âš ï¸ é‡è¦**: æ—¥æœŸåˆ—åœ¨æ­¤æ­¥éª¤ä¼šè¢«è½¬ä¸ºç©ºå­—ç¬¦ä¸²,éœ€è¦åœ¨åç»­æŸ¥è¯¢æ—¶é‡æ–°è½¬æ¢:
```python
df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')
```

---

### 2.3 `merge_with_existing(new_df)` - æ•°æ®åˆå¹¶

**ä½ç½®**: [data_processor.py:155-184](../../backend/data_processor.py#L155-L184)

**åŠŸèƒ½**: å°†æ–°æ•°æ®ä¸ç°æœ‰ CSV åˆå¹¶,å»é‡å¹¶ç»Ÿè®¡

**å®ç°ç»†èŠ‚**:
```python
def merge_with_existing(self, new_df):
    if self.merged_csv.exists():
        print(f"è¯»å–ç°æœ‰æ•°æ®: {self.merged_csv}")
        existing_df = pd.read_csv(self.merged_csv, encoding='utf-8-sig')

        # åˆå¹¶æ•°æ®
        merged_df = pd.concat([existing_df, new_df], ignore_index=True)

        # å»é‡ - æ ¹æ®ä¿å•å·å’ŒæŠ•ä¿ç¡®è®¤æ—¶é—´
        if 'ä¿å•å·' in merged_df.columns and 'æŠ•ä¿ç¡®è®¤æ—¶é—´' in merged_df.columns:
            merged_df = merged_df.drop_duplicates(
                subset=['ä¿å•å·', 'æŠ•ä¿ç¡®è®¤æ—¶é—´'],
                keep='last'
            )

        print(f"  åˆå¹¶å®Œæˆ: {len(existing_df)} + {len(new_df)} = {len(merged_df)} è¡Œ")
    else:
        print(f"  æœªæ‰¾åˆ°ç°æœ‰æ•°æ®,åˆ›å»ºæ–°æ–‡ä»¶")
        merged_df = new_df

    return merged_df
```

**å…³é”®å‚æ•°è§£æ**:
- `encoding='utf-8-sig'`: è¯»å–å¸¦ BOM çš„ UTF-8 æ–‡ä»¶
- `ignore_index=True`: é‡æ–°ç”Ÿæˆ 0-N çš„è¿ç»­ç´¢å¼•
- `keep='last'`: ä¿ç•™é‡å¤è®°å½•ä¸­çš„æœ€åä¸€æ¡

**æ€§èƒ½ä¼˜åŒ–å»ºè®®**:
```python
# âŒ ä¸æ¨è: é€è¡Œè¿½åŠ (O(nÂ²) å¤æ‚åº¦)
for _, row in new_df.iterrows():
    existing_df = existing_df.append(row)

# âœ… æ¨è: ä¸€æ¬¡æ€§åˆå¹¶(O(n) å¤æ‚åº¦)
merged_df = pd.concat([existing_df, new_df], ignore_index=True)
```

**å†…å­˜ä¼˜åŒ–**:
- å¤§æ–‡ä»¶(>1GB)å¯ä½¿ç”¨ `pd.read_csv(chunksize=10000)` åˆ†å—è¯»å–
- åˆå¹¶åç«‹å³åˆ é™¤ä¸­é—´å˜é‡: `del existing_df, new_df`

---

### 2.4 `scan_and_process_new_files()` - æ‰¹é‡å¤„ç†

**ä½ç½®**: [data_processor.py:191-237](../../backend/data_processor.py#L191-L237)

**åŠŸèƒ½**: æ‰«æ data ç›®å½•,æ‰¹é‡å¤„ç†æ‰€æœ‰æ–° Excel æ–‡ä»¶

**å®ç°æµç¨‹**:

#### æ­¥éª¤ 1: æ‰«æç›®å½•
```python
excel_files = list(self.data_dir.glob('*.xlsx')) + list(self.data_dir.glob('*.xls'))
```
- ä½¿ç”¨ `pathlib.Path.glob()` æŸ¥æ‰¾æ–‡ä»¶
- æ”¯æŒ `.xlsx` å’Œ `.xls` ä¸¤ç§æ ¼å¼

#### æ­¥éª¤ 2: æ‰¹é‡å¤„ç†
```python
all_new_data = []
for excel_file in excel_files:
    try:
        # å¤„ç†å•ä¸ªæ–‡ä»¶
        df = self.process_new_excel(excel_file)
        all_new_data.append(df)

        # å¤„ç†å®Œæˆåç§»åŠ¨åˆ°å·²å¤„ç†ç›®å½•
        processed_dir = self.data_dir / 'processed'
        processed_dir.mkdir(exist_ok=True)

        new_path = processed_dir / f"{excel_file.stem}_processed_{datetime.now().strftime('%Y%m%d_%H%M%S')}{excel_file.suffix}"
        excel_file.rename(new_path)
        print(f"  æ–‡ä»¶å·²ç§»åŠ¨: {new_path}")

    except Exception as e:
        print(f"  å¤„ç†å¤±è´¥: {e}")
```

**å¼‚å¸¸å¤„ç†ç­–ç•¥**:
- âœ… **å•æ–‡ä»¶å¤±è´¥ä¸ä¸­æ–­**: ä½¿ç”¨ `try-except` æ•è·å•æ–‡ä»¶å¼‚å¸¸
- âœ… **è®°å½•é”™è¯¯ä¿¡æ¯**: `print(f"å¤„ç†å¤±è´¥: {e}")`
- âœ… **ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª**: ä¸æŠ›å‡ºå¼‚å¸¸,ä¿è¯å…¶ä»–æ–‡ä»¶æ­£å¸¸å¤„ç†

#### æ­¥éª¤ 3: åˆå¹¶ä¸ä¿å­˜
```python
if all_new_data:
    # åˆå¹¶æ‰€æœ‰æ–°æ•°æ®
    combined_new = pd.concat(all_new_data, ignore_index=True)

    # ä¸ç°æœ‰æ•°æ®åˆå¹¶
    final_df = self.merge_with_existing(combined_new)

    # ä¿å­˜
    self.save_merged_data(final_df)

    print(f"æ•°æ®æ›´æ–°å®Œæˆ!")
```

**è§¦å‘æ–¹å¼**:
1. **æ‰‹åŠ¨è§¦å‘**: `python backend/data_processor.py`
2. **API è§¦å‘**: `POST /api/refresh` (è§ [api_server.py:21-37](../../backend/api_server.py#L21-L37))
3. **å®šæ—¶ä»»åŠ¡**: å¯é…ç½® cron å®šæ—¶æ‰§è¡Œ

---

## ğŸ¯ ä¸‰ã€ä¸šåŠ¡è§„åˆ™å®ç°

### 3.1 è´Ÿä¿è´¹å¤„ç†(é€€ä¿/æ‰¹æ”¹)

**ä¸šåŠ¡åœºæ™¯**:
- é€€ä¿: `ç­¾å•/æ‰¹æ”¹ä¿è´¹ < 0` (ä¾‹å¦‚: `-5000.00`)
- æ‰¹æ”¹å‡ä¿: éƒ¨åˆ†é€€ä¿å¯¼è‡´ä¿è´¹ä¸ºè´Ÿ

**å¤„ç†ç­–ç•¥**:
```python
# âœ… ä¿ç•™è´Ÿæ•°,ä¸åšä¿®æ”¹
df[col] = pd.to_numeric(df[col], errors='coerce')
```

**æŸ¥è¯¢æ—¶çš„å¤„ç†**:
- **ä¿è´¹ç»Ÿè®¡**: ç›´æ¥ `sum()`,è´Ÿæ•°ä¼šè‡ªåŠ¨æŠµæ¶ˆæ­£æ•°
- **ä¿å•ä»¶æ•°**: éœ€è¦è¿‡æ»¤ `>= 50` çš„è®°å½•(è§ [data_processor.py:507-509](../../backend/data_processor.py#L507-L509))

```python
# ä¿å•ä»¶æ•°: è¿‡æ»¤å°é¢/è´Ÿä¿è´¹
period_data = period_data[period_data['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50]
daily_stats = period_data.groupby('weekday_index').size()
```

**æ³¨æ„äº‹é¡¹**:
- âŒ ä¸è¦ç”¨ `abs()` å–ç»å¯¹å€¼ - ä¼šå¯¼è‡´é€€ä¿ä¹Ÿè®¡å…¥æ­£ä¿è´¹
- âœ… å‰ç«¯å±•ç¤ºæ—¶å¯ç”¨çº¢è‰²æ ‡æ³¨è´Ÿæ•°

---

### 3.2 é›¶æ‰‹ç»­è´¹åœºæ™¯

**ä¸šåŠ¡åœºæ™¯**:
- æ–°èƒ½æºè½¦é™©: éƒ¨åˆ†åœ°åŒºæ‰‹ç»­è´¹ä¸º 0
- æ´»åŠ¨æœŸé—´: å…æ‰‹ç»­è´¹ä¿ƒé”€

**å¤„ç†ç­–ç•¥**:
```python
# âœ… ä¿ç•™ 0 å€¼,ä¸åšä¿®æ”¹
commission_day = sum_float(day_df['æ‰‹ç»­è´¹å«ç¨'])  # 0 ä¹Ÿä¼šè¢«ç´¯åŠ 
```

**éªŒè¯é€»è¾‘**:
- âŒ ä¸è¦åˆ¤æ–­ `if commission > 0:` - ä¼šå¿½ç•¥åˆæ³•çš„ 0 å€¼
- âœ… å…è®¸ 0 å€¼å­˜åœ¨,å‰ç«¯å¯ç‰¹æ®Šå±•ç¤º

---

### 3.3 æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ–

**æ”¯æŒçš„æ—¥æœŸæ ¼å¼**:
1. **ISO 8601**: `2025-11-08` (æ¨è)
2. **æ–œæ åˆ†éš”**: `2025/11/08`
3. **æ— åˆ†éš”ç¬¦**: `20251108`
4. **Excel åºåˆ—å·**: `44500` (è‡ªåŠ¨è½¬æ¢)

**æ ‡å‡†åŒ–ä»£ç **:
```python
df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')
```

**API è¿”å›æ ¼å¼**:
```python
# ç»Ÿä¸€è½¬æ¢ä¸º YYYY-MM-DD æ ¼å¼
latest_date.strftime('%Y-%m-%d')  # '2025-11-08'
```

**æ—¶åŒºå¤„ç†**:
- å½“å‰ä¸æ¶‰åŠæ—¶åŒºè½¬æ¢(æ‰€æœ‰æ•°æ®å‡ä¸ºæœ¬åœ°æ—¶é—´)
- å¦‚éœ€æ”¯æŒæ—¶åŒº: `pd.to_datetime(..., utc=True)`

---

### 3.4 ç¼ºå¤±å€¼å¡«å……ç­–ç•¥

**å¡«å……è§„åˆ™**:
```python
df = df.fillna('')  # ç»Ÿä¸€å¡«å……ä¸ºç©ºå­—ç¬¦ä¸²
```

**å„å­—æ®µç¼ºå¤±å€¼å¤„ç†**:

| å­—æ®µç±»å‹ | ç¼ºå¤±å€¼å¤„ç† | æŸ¥è¯¢æ—¶å¤„ç† |
|---------|-----------|-----------|
| æ—¥æœŸå­—æ®µ | `NaT` â†’ `''` | `pd.to_datetime(..., errors='coerce')` é‡æ–°è½¬æ¢ |
| æ•°å€¼å­—æ®µ | `NaN` â†’ `''` | `pd.to_numeric(..., errors='coerce')` é‡æ–°è½¬æ¢ |
| æ–‡æœ¬å­—æ®µ | `None` â†’ `''` | ç›´æ¥ä½¿ç”¨ç©ºå­—ç¬¦ä¸² |

**æŸ¥è¯¢æ—¶çš„é‡æ–°è½¬æ¢** (å¿…éœ€):
```python
# è¯»å– CSV åå¿…é¡»é‡æ–°è½¬æ¢æ—¥æœŸ
df = pd.read_csv(self.merged_csv, encoding='utf-8-sig')
df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')
```

**ä¸ºä»€ä¹ˆéœ€è¦é‡æ–°è½¬æ¢**:
- CSV æ–‡ä»¶ä¸ä¿ç•™æ•°æ®ç±»å‹ä¿¡æ¯
- `pd.read_csv()` é»˜è®¤å°†æ—¥æœŸè¯»ä¸ºå­—ç¬¦ä¸²
- å¿…é¡»æ˜¾å¼è½¬æ¢æ‰èƒ½è¿›è¡Œæ—¥æœŸè¿ç®—

---

## âš¡ å››ã€æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 4.1 Pandas ä¼˜åŒ–æ¨¡å¼

#### ä¼˜åŒ– 1: ä½¿ç”¨å‘é‡åŒ–æ“ä½œ

âŒ **ä½æ•ˆ**: é€è¡Œè¿­ä»£
```python
for _, row in df.iterrows():
    if row['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50:
        count += 1
```

âœ… **é«˜æ•ˆ**: å‘é‡åŒ–è¿‡æ»¤
```python
count = len(df[df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50])
```

**æ€§èƒ½æå‡**: 100x - 1000x

---

#### ä¼˜åŒ– 2: é¿å…å¤šæ¬¡ DataFrame å¤åˆ¶

âŒ **ä½æ•ˆ**: é“¾å¼è¿‡æ»¤(æ¯æ¬¡åˆ›å»ºæ–° DataFrame)
```python
df = df[df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50]
df = df[df['æ˜¯å¦ç»­ä¿'] == 'æ˜¯']
df = df[df['ä¸‰çº§æœºæ„'] == 'è¾¾å·']
```

âœ… **é«˜æ•ˆ**: åˆå¹¶æ¡ä»¶
```python
mask = (df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50) & \
       (df['æ˜¯å¦ç»­ä¿'] == 'æ˜¯') & \
       (df['ä¸‰çº§æœºæ„'] == 'è¾¾å·')
df = df[mask]
```

**å†…å­˜èŠ‚çœ**: é¿å…åˆ›å»º 3 ä¸ªä¸­é—´ DataFrame

---

#### ä¼˜åŒ– 3: ä½¿ç”¨ `low_memory=False` å¤„ç†å¤§æ–‡ä»¶

```python
# âœ… æ¨è: å¤§æ–‡ä»¶è¯»å–æ—¶æŒ‡å®š
df = pd.read_csv(self.merged_csv, encoding='utf-8-sig', low_memory=False)
```

**è¯´æ˜**:
- `low_memory=True` (é»˜è®¤): åˆ†å—è¯»å–,å¯èƒ½å¯¼è‡´æ•°æ®ç±»å‹æ¨æ–­ä¸ä¸€è‡´
- `low_memory=False`: ä¸€æ¬¡æ€§è¯»å–,ç¡®ä¿ç±»å‹ä¸€è‡´(é€‚ç”¨äº <1GB æ–‡ä»¶)

---

### 4.2 å†…å­˜ç®¡ç†

#### æŠ€å·§ 1: æ˜¾å¼åˆ é™¤ä¸­é—´å˜é‡

```python
existing_df = pd.read_csv(...)
new_df = pd.read_excel(...)
merged_df = pd.concat([existing_df, new_df])

# âœ… ç«‹å³é‡Šæ”¾å†…å­˜
del existing_df, new_df
```

#### æŠ€å·§ 2: ä½¿ç”¨ `dtype` æŒ‡å®šæ•°æ®ç±»å‹(é€‚ç”¨äºå·²çŸ¥åˆ—)

```python
# âœ… æŒ‡å®šç±»å‹å¯å‡å°‘å†…å­˜å ç”¨
dtype_dict = {
    'ä¿å•å·': 'string',
    'ç­¾å•/æ‰¹æ”¹ä¿è´¹': 'float32',  # è€Œé float64
    'ç­¾å•æ•°é‡': 'int32'           # è€Œé int64
}
df = pd.read_csv(..., dtype=dtype_dict)
```

**å†…å­˜èŠ‚çœ**: `float64` â†’ `float32` å‡å°‘ 50% å†…å­˜

#### æŠ€å·§ 3: åˆ†å—å¤„ç†å¤§æ–‡ä»¶

```python
# âœ… è¶…å¤§æ–‡ä»¶(>1GB)ä½¿ç”¨åˆ†å—
chunk_size = 10000
chunks = []
for chunk in pd.read_csv(..., chunksize=chunk_size):
    # å¤„ç†æ¯ä¸ªåˆ†å—
    chunk = chunk[chunk['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50]
    chunks.append(chunk)

df = pd.concat(chunks, ignore_index=True)
```

---

### 4.3 å¤§æ–‡ä»¶å¤„ç†ç­–ç•¥

**æ–‡ä»¶å¤§å°åˆ†çº§**:
- **å°æ–‡ä»¶** (<10MB): ç›´æ¥ `pd.read_csv()` / `pd.read_excel()`
- **ä¸­æ–‡ä»¶** (10MB - 100MB): ä½¿ç”¨ `low_memory=False`
- **å¤§æ–‡ä»¶** (100MB - 1GB): ä½¿ç”¨ `dtype` æŒ‡å®šç±»å‹
- **è¶…å¤§æ–‡ä»¶** (>1GB): ä½¿ç”¨ `chunksize` åˆ†å—å¤„ç†

**å½“å‰é¡¹ç›®å®è·µ**:
- è½¦é™©æ¸…å•åˆå¹¶ CSV: çº¦ 20MB (ä¸­æ–‡ä»¶)
- ä½¿ç”¨ `low_memory=False` ç¡®ä¿ç±»å‹ä¸€è‡´

---

### 4.4 å¹¶å‘å¤„ç†è€ƒè™‘

**å½“å‰æ¶æ„**: å•è¿›ç¨‹é¡ºåºå¤„ç†

**å¯ä¼˜åŒ–æ–¹å‘**:
```python
from concurrent.futures import ProcessPoolExecutor

def process_file(excel_file):
    df = pd.read_excel(excel_file)
    df = _clean_data(df)
    return df

# âœ… å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†
with ProcessPoolExecutor(max_workers=4) as executor:
    results = executor.map(process_file, excel_files)
    all_new_data = list(results)
```

**æ³¨æ„äº‹é¡¹**:
- âš ï¸ å¤šè¿›ç¨‹ä¼šå¢åŠ å†…å­˜å ç”¨(æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹å†…å­˜)
- âš ï¸ Windows ä¸‹éœ€è¦ `if __name__ == '__main__':` ä¿æŠ¤
- âœ… é€‚ç”¨äºæ–‡ä»¶æ•°é‡å¤š(>10)ä¸”å•æ–‡ä»¶å°(<10MB)çš„åœºæ™¯

---

## ğŸ” äº”ã€é”™è¯¯å¤„ç†ä¸æ—¥å¿—

### 5.1 å¼‚å¸¸æ•è·æœºåˆ¶

#### æ–‡ä»¶å¤„ç†å¼‚å¸¸

```python
try:
    df = self.process_new_excel(excel_file)
    all_new_data.append(df)
except Exception as e:
    print(f"  å¤„ç†å¤±è´¥: {e}")
    # âœ… ä¸ä¸­æ–­,ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
```

**æ•è·çš„å¼‚å¸¸ç±»å‹**:
- `FileNotFoundError`: æ–‡ä»¶ä¸å­˜åœ¨
- `PermissionError`: æ–‡ä»¶è¢«å ç”¨(Windows)
- `xlrd.biffh.XLRDError`: Excel æ–‡ä»¶æŸå
- `MemoryError`: å†…å­˜ä¸è¶³
- `pd.errors.ParserError`: CSV è§£æå¤±è´¥

---

#### API å¼‚å¸¸å¤„ç† ([api_server.py:26-37](../../backend/api_server.py#L26-L37))

```python
@app.route('/api/refresh', methods=['POST'])
def refresh_data():
    try:
        processor.scan_and_process_new_files()
        return jsonify({
            'success': True,
            'message': 'æ•°æ®åˆ·æ–°æˆåŠŸ',
            'latest_date': processor.get_latest_date()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ•°æ®åˆ·æ–°å¤±è´¥: {str(e)}'
        }), 500
```

**ç»Ÿä¸€å“åº”æ ¼å¼**:
- æˆåŠŸ: `{ success: true, data: {...} }`
- å¤±è´¥: `{ success: false, message: "é”™è¯¯ä¿¡æ¯" }`, HTTP 500

---

### 5.2 æ—¥å¿—è®°å½•æ ‡å‡†

**å½“å‰æ—¥å¿—çº§åˆ«**:
- `print()`: è¾“å‡ºåˆ° stdout (ç»ˆç«¯/æ—¥å¿—æ–‡ä»¶)
- æ— ç»“æ„åŒ–æ—¥å¿—(æœªä½¿ç”¨ `logging` æ¨¡å—)

**æ—¥å¿—å†…å®¹**:
```python
print(f"æ­£åœ¨å¤„ç†Excelæ–‡ä»¶: {excel_path}")               # INFO
print(f"  è¯»å–æˆåŠŸ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")  # INFO
print(f"  æ•°æ®æ¸…æ´—å®Œæˆ")                                # INFO
print(f"  å¤„ç†å¤±è´¥: {e}")                                # ERROR
```

**æ”¹è¿›å»ºè®®** (ä½¿ç”¨ `logging` æ¨¡å—):
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('backend/backend.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# ä½¿ç”¨
logger.info(f"æ­£åœ¨å¤„ç†Excelæ–‡ä»¶: {excel_path}")
logger.error(f"å¤„ç†å¤±è´¥: {e}", exc_info=True)  # è®°å½•å®Œæ•´å †æ ˆ
```

---

### 5.3 ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º

**API é”™è¯¯æç¤ºè®¾è®¡**:

| é”™è¯¯åœºæ™¯ | HTTP çŠ¶æ€ç  | é”™è¯¯æ¶ˆæ¯ | ç”¨æˆ·æ“ä½œå»ºè®® |
|---------|-----------|---------|------------|
| æœªæ‰¾åˆ°æ•°æ® | 404 | "æœªæ‰¾åˆ°æ•°æ®" | è¯·å…ˆä¸Šä¼  Excel æ–‡ä»¶ |
| æ–‡ä»¶æ ¼å¼é”™è¯¯ | 500 | "Excel æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®" | è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸º .xlsx/.xls |
| å¿…å¡«åˆ—ç¼ºå¤± | 500 | "ç¼ºå°‘å¿…å¡«åˆ—: ä¿å•å·" | è¯·ç¡®ä¿ Excel åŒ…å«æ‰€æœ‰å¿…å¡«åˆ— |
| æ—¥æœŸæ ¼å¼é”™è¯¯ | 500 | "æŠ•ä¿ç¡®è®¤æ—¶é—´æ ¼å¼ä¸æ­£ç¡®" | è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ |
| å†…å­˜ä¸è¶³ | 500 | "æ–‡ä»¶è¿‡å¤§,å†…å­˜ä¸è¶³" | è¯·åˆ†æ‰¹ä¸Šä¼ è¾ƒå°çš„æ–‡ä»¶ |

**å‰ç«¯å±•ç¤ºå»ºè®®**:
```javascript
if (!response.success) {
  // âœ… ç”¨æˆ·å‹å¥½çš„æç¤º
  toast.error(response.message)

  // âŒ ä¸å‹å¥½çš„æç¤º
  console.error(response.message)
}
```

---

## ğŸ“– å…­ã€å®é™…ä»£ç ç¤ºä¾‹ä¸æœ€ä½³å®è·µ

### 6.1 å®Œæ•´çš„æ–‡ä»¶å¤„ç†æµç¨‹

```python
from pathlib import Path
from data_processor import DataProcessor

# åˆå§‹åŒ–å¤„ç†å™¨
processor = DataProcessor(
    data_dir='data',
    staff_mapping_file='ä¸šåŠ¡å‘˜æœºæ„å›¢é˜Ÿå½’å±.json'
)

# æ‰¹é‡å¤„ç†æ–°æ–‡ä»¶
processor.scan_and_process_new_files()

# è¾“å‡ºç¤ºä¾‹:
# ==========================================
# æ‰¾åˆ° 2 ä¸ªExcelæ–‡ä»¶
# æ­£åœ¨å¤„ç†Excelæ–‡ä»¶: data/è½¦é™©æ¸…å•_2025å¹´10æœˆ.xlsx
#   è¯»å–æˆåŠŸ: 1234 è¡Œ, 45 åˆ—
#   æ•°æ®æ¸…æ´—å®Œæˆ
#   åˆå¹¶å®Œæˆ: 5678 + 1234 = 6912 è¡Œ
#   æ–‡ä»¶å·²ç§»åŠ¨: data/processed/è½¦é™©æ¸…å•_2025å¹´10æœˆ_processed_20251108_143025.xlsx
# æ­£åœ¨å¤„ç†Excelæ–‡ä»¶: data/è½¦é™©æ¸…å•_2025å¹´11æœˆ.xlsx
#   è¯»å–æˆåŠŸ: 890 è¡Œ, 45 åˆ—
#   æ•°æ®æ¸…æ´—å®Œæˆ
#   åˆå¹¶å®Œæˆ: 6912 + 890 = 7802 è¡Œ
#   æ–‡ä»¶å·²ç§»åŠ¨: data/processed/è½¦é™©æ¸…å•_2025å¹´11æœˆ_processed_20251108_143030.xlsx
# æ•°æ®æ›´æ–°å®Œæˆ!
```

---

### 6.2 å•æ–‡ä»¶å¤„ç†(æ‰‹åŠ¨æ§åˆ¶)

```python
from pathlib import Path
import pandas as pd
from data_processor import DataProcessor

processor = DataProcessor()

# æ­¥éª¤ 1: å¤„ç†å•ä¸ª Excel
excel_path = Path('data/è½¦é™©æ¸…å•_2025å¹´10æœˆ.xlsx')
df = processor.process_new_excel(excel_path)

# æ­¥éª¤ 2: æ£€æŸ¥æ•°æ®
print(f"å¤„ç†åæ•°æ®: {len(df)} è¡Œ")
print(f"åˆ—å: {df.columns.tolist()}")

# æ­¥éª¤ 3: åˆå¹¶åˆ°ç°æœ‰æ•°æ®
merged_df = processor.merge_with_existing(df)

# æ­¥éª¤ 4: ä¿å­˜
processor.save_merged_data(merged_df)

print("å•æ–‡ä»¶å¤„ç†å®Œæˆ!")
```

---

### 6.3 æ•°æ®éªŒè¯ä¸è´¨é‡æ£€æŸ¥

```python
import pandas as pd

# è¯»å–åˆå¹¶åçš„æ•°æ®
df = pd.read_csv('è½¦é™©æ¸…å•_2025å¹´10-11æœˆ_åˆå¹¶.csv', encoding='utf-8-sig', low_memory=False)

# ===== æ•°æ®è´¨é‡æ£€æŸ¥ =====

# 1. æ£€æŸ¥å¿…å¡«åˆ—æ˜¯å¦å­˜åœ¨
required_cols = ['ä¿å•å·', 'ä¸šåŠ¡å‘˜', 'æŠ•ä¿ç¡®è®¤æ—¶é—´', 'ç­¾å•/æ‰¹æ”¹ä¿è´¹']
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    print(f"âŒ ç¼ºå°‘å¿…å¡«åˆ—: {missing_cols}")
else:
    print(f"âœ… å¿…å¡«åˆ—å®Œæ•´")

# 2. æ£€æŸ¥ä¿å•å·å”¯ä¸€æ€§
df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')
duplicates = df[df.duplicated(subset=['ä¿å•å·', 'æŠ•ä¿ç¡®è®¤æ—¶é—´'], keep=False)]
if len(duplicates) > 0:
    print(f"âš ï¸  å‘ç° {len(duplicates)} æ¡é‡å¤è®°å½•")
else:
    print(f"âœ… æ— é‡å¤è®°å½•")

# 3. æ£€æŸ¥æ—¥æœŸèŒƒå›´
latest_date = df['æŠ•ä¿ç¡®è®¤æ—¶é—´'].max()
earliest_date = df['æŠ•ä¿ç¡®è®¤æ—¶é—´'].min()
print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {earliest_date.date()} ~ {latest_date.date()}")

# 4. æ£€æŸ¥ä¿è´¹åˆ†å¸ƒ
print(f"ğŸ’° ä¿è´¹ç»Ÿè®¡:")
print(f"  - æœ€å°å€¼: {df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'].min():.2f}")
print(f"  - æœ€å¤§å€¼: {df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'].max():.2f}")
print(f"  - å¹³å‡å€¼: {df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'].mean():.2f}")
print(f"  - è´Ÿä¿è´¹è®°å½•æ•°: {len(df[df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] < 0])}")

# 5. æ£€æŸ¥ä¸šåŠ¡å‘˜æ˜ å°„è¦†ç›–ç‡
staff_in_data = set(df['ä¸šåŠ¡å‘˜'].dropna().unique())
staff_in_mapping = set()  # ä»æ˜ å°„æ–‡ä»¶ä¸­æå–
coverage = len(staff_in_mapping & staff_in_data) / len(staff_in_data) * 100
print(f"ğŸ‘¥ ä¸šåŠ¡å‘˜æ˜ å°„è¦†ç›–ç‡: {coverage:.1f}%")
```

---

### 6.4 æœ€ä½³å®è·µæ€»ç»“

#### âœ… æ¨èåšæ³•

1. **ä½¿ç”¨ pathlib å¤„ç†è·¯å¾„**
   ```python
   # âœ… æ¨è
   from pathlib import Path
   project_root = Path(__file__).parent.parent
   csv_path = project_root / 'è½¦é™©æ¸…å•_2025å¹´10-11æœˆ_åˆå¹¶.csv'

   # âŒ ä¸æ¨è
   import os
   csv_path = os.path.join(os.getcwd(), 'è½¦é™©æ¸…å•_2025å¹´10-11æœˆ_åˆå¹¶.csv')
   ```

2. **è¯»å– CSV æ—¶å§‹ç»ˆæŒ‡å®š encoding**
   ```python
   # âœ… æ¨è
   df = pd.read_csv(csv_path, encoding='utf-8-sig')

   # âŒ ä¸æ¨è(å¯èƒ½ä¹±ç )
   df = pd.read_csv(csv_path)
   ```

3. **æŸ¥è¯¢å‰é‡æ–°è½¬æ¢æ—¥æœŸç±»å‹**
   ```python
   # âœ… æ¨è
   df = pd.read_csv(csv_path, encoding='utf-8-sig')
   df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')

   # âŒ ä¸æ¨è(æ—¥æœŸè¿ç®—ä¼šæŠ¥é”™)
   df = pd.read_csv(csv_path, encoding='utf-8-sig')
   df['æŠ•ä¿ç¡®è®¤æ—¶é—´'].max()  # TypeError: '>' not supported
   ```

4. **ä½¿ç”¨å‘é‡åŒ–æ“ä½œ**
   ```python
   # âœ… æ¨è
   count = len(df[df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50])

   # âŒ ä¸æ¨è
   count = 0
   for _, row in df.iterrows():
       if row['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50:
           count += 1
   ```

5. **å¼‚å¸¸æ•è·ä¸ä¸­æ–­æ‰¹é‡å¤„ç†**
   ```python
   # âœ… æ¨è
   for file in files:
       try:
           process(file)
       except Exception as e:
           logger.error(f"å¤„ç†å¤±è´¥: {e}")
           continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª

   # âŒ ä¸æ¨è(ä¸€ä¸ªæ–‡ä»¶å¤±è´¥å¯¼è‡´å…¨éƒ¨ä¸­æ–­)
   for file in files:
       process(file)  # æœªæ•è·å¼‚å¸¸
   ```

#### âŒ å¸¸è§é™·é˜±

1. **é“¾å¼èµ‹å€¼è­¦å‘Š**
   ```python
   # âŒ ä¼šè§¦å‘ SettingWithCopyWarning
   df[df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50]['æ˜¯å¦ç»­ä¿'] = 'æ˜¯'

   # âœ… ä½¿ç”¨ .loc
   df.loc[df['ç­¾å•/æ‰¹æ”¹ä¿è´¹'] >= 50, 'æ˜¯å¦ç»­ä¿'] = 'æ˜¯'
   ```

2. **æ—¥æœŸæ¯”è¾ƒå‰æœªè½¬æ¢**
   ```python
   # âŒ æ—¥æœŸæ˜¯å­—ç¬¦ä¸²,æ¯”è¾ƒç»“æœé”™è¯¯
   df = pd.read_csv(csv_path)
   df = df[df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] > '2025-11-01']  # å­—ç¬¦ä¸²æ¯”è¾ƒ

   # âœ… å…ˆè½¬æ¢ä¸ºæ—¥æœŸ
   df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')
   df = df[df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] > pd.to_datetime('2025-11-01')]
   ```

3. **å¿½ç•¥ errors='coerce'**
   ```python
   # âŒ æ— æ•ˆæ—¥æœŸä¼šæŠ›å‡ºå¼‚å¸¸
   df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'])

   # âœ… æ— æ•ˆæ—¥æœŸè½¬ä¸º NaT
   df['æŠ•ä¿ç¡®è®¤æ—¶é—´'] = pd.to_datetime(df['æŠ•ä¿ç¡®è®¤æ—¶é—´'], errors='coerce')
   ```

4. **ä½¿ç”¨ append() è¿½åŠ è¡Œ** (Pandas 1.4+ å·²å¼ƒç”¨)
   ```python
   # âŒ å·²å¼ƒç”¨,ä¸”æ€§èƒ½å·®
   for _, row in df.iterrows():
       new_df = new_df.append(row)

   # âœ… ä½¿ç”¨ concat
   new_df = pd.concat([new_df, df], ignore_index=True)
   ```

---

## ğŸ”— ä¸ƒã€ç›¸å…³èµ„æº

### å…³é”®ä»£ç ä½ç½®
- [backend/data_processor.py](../../backend/data_processor.py) - æ•°æ®å¤„ç†æ ¸å¿ƒé€»è¾‘
  - [L107-236](../../backend/data_processor.py#L107-L236): æ–‡ä»¶å¤„ç†ã€æ¸…æ´—ã€åˆå¹¶
  - [L129-153](../../backend/data_processor.py#L129-L153): æ•°æ®æ¸…æ´—è§„åˆ™
  - [L155-184](../../backend/data_processor.py#L155-L184): æ•°æ®åˆå¹¶ä¸å»é‡
- [backend/api_server.py](../../backend/api_server.py) - Flask API æœåŠ¡
  - [L21-37](../../backend/api_server.py#L21-L37): æ•°æ®åˆ·æ–°æ¥å£

### ç›¸å…³ Skills
- [analyzing-auto-insurance-data](../analyzing-auto-insurance-data/SKILL.md) - æ•°æ®åˆ†ææ ¸å¿ƒæ–¹æ³•
- [api-endpoint-design](../SKILLS_ROADMAP.md#4-api-endpoint-design) (å¾…å¼€å‘) - API è§„èŒƒæ–‡æ¡£

### æ–‡æ¡£èµ„æº
- [ARCHITECTURE.md](../../docs/ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„æ–‡æ¡£
- [PRODUCT_SPEC.md](../../docs/PRODUCT_SPEC.md) - äº§å“éœ€æ±‚æ–‡æ¡£

---

## âœ… æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **æ•°æ®æµè½¬**: Excel â†’ æ¸…æ´— â†’ åˆå¹¶ â†’ å»é‡ â†’ CSV
2. **å»é‡ç­–ç•¥**: ä¿å•å· + æŠ•ä¿ç¡®è®¤æ—¶é—´, `keep='last'`
3. **æ¸…æ´—æ­¥éª¤**: åˆ é™¤ç©ºè¡Œ â†’ æ—¥æœŸè½¬æ¢ â†’ æ•°å€¼è½¬æ¢ â†’ å¡«å……ç©ºå€¼
4. **æ€§èƒ½ä¼˜åŒ–**: å‘é‡åŒ–æ“ä½œã€é¿å…é“¾å¼è¿‡æ»¤ã€æ˜¾å¼åˆ é™¤ä¸­é—´å˜é‡
5. **å¼‚å¸¸å¤„ç†**: å•æ–‡ä»¶å¤±è´¥ä¸ä¸­æ–­ã€è®°å½•é”™è¯¯ä¿¡æ¯ã€ç”¨æˆ·å‹å¥½æç¤º

### Token èŠ‚çœä¼°ç®—

- **æ¯æ¬¡å¯¹è¯èŠ‚çœ**: 3000-5000 tokens
- **å¹´ä½¿ç”¨æ¬¡æ•°**: çº¦ 30 æ¬¡(æ•°æ®å¤„ç†é—®é¢˜)
- **å¹´æ€»èŠ‚çœ**: 90,000 - 150,000 tokens

### é€‚ç”¨åœºæ™¯

âœ… é€‚ç”¨:
- Excel æ–‡ä»¶ä¸Šä¼ ä¸å¤„ç†
- æ•°æ®æ¸…æ´—è§„åˆ™ä¿®æ”¹
- åˆå¹¶é€»è¾‘è°ƒæ•´
- æ€§èƒ½ä¼˜åŒ–
- å¼‚å¸¸æ’æŸ¥

âŒ ä¸é€‚ç”¨:
- ä¸šåŠ¡é€»è¾‘æŸ¥è¯¢(ä½¿ç”¨ `analyzing-auto-insurance-data`)
- API æ¥å£è®¾è®¡(ä½¿ç”¨ `api-endpoint-design`)
- å‰ç«¯ç»„ä»¶å¼€å‘(ä½¿ç”¨ `vue-component-dev`)

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Claude Code AI Assistant
**åˆ›å»ºæ—¥æœŸ**: 2025-11-08
**ä¸‹æ¬¡å®¡æŸ¥**: 2025-11-22
